//
//  StorageManager.swift
//  Dayflow
//

import Foundation
import GRDB
import Sentry

extension DateFormatter {
    static let yyyyMMdd: DateFormatter = {
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd"
        formatter.timeZone = Calendar.current.timeZone
        return formatter
    }()
}

extension Date {
    /// Calculates the "day" based on a 4 AM start time.
    /// Returns the date string (YYYY-MM-DD) and the Date objects for the start and end of that day.
    func getDayInfoFor4AMBoundary() -> (dayString: String, startOfDay: Date, endOfDay: Date) {
        let calendar = Calendar.current
        guard let fourAMToday = calendar.date(bySettingHour: 4, minute: 0, second: 0, of: self) else {
            print("Error: Could not calculate 4 AM for date \(self). Falling back to standard day.")
            let start = calendar.startOfDay(for: self)
            let end = calendar.date(byAdding: .day, value: 1, to: start)!
            return (DateFormatter.yyyyMMdd.string(from: start), start, end)
        }

        let startOfDay: Date
        if self < fourAMToday {
            startOfDay = calendar.date(byAdding: .day, value: -1, to: fourAMToday)!
        } else {
            startOfDay = fourAMToday
        }
        let endOfDay = calendar.date(byAdding: .day, value: 1, to: startOfDay)!
        let dayString = DateFormatter.yyyyMMdd.string(from: startOfDay)
        return (dayString, startOfDay, endOfDay)
    }
}


/// File + database persistence used by screen‚Äërecorder & Gemini pipeline.
///
/// _No_ `@MainActor` isolation ‚áí can be called from any thread/actor.
/// If you add UI‚Äëtouching methods later, isolate **those** individually.
protocol StorageManaging: Sendable {
    // Recording‚Äëchunk lifecycle
    func nextFileURL() -> URL
    func registerChunk(url: URL)
    func markChunkCompleted(url: URL)
    func markChunkFailed(url: URL)

    // Fetch unprocessed (completed + not yet batched) chunks
    func fetchUnprocessedChunks(olderThan oldestAllowed: Int) -> [RecordingChunk]
    func fetchChunksInTimeRange(startTs: Int, endTs: Int) -> [RecordingChunk]

    // Analysis‚Äëbatch management
    func saveBatch(startTs: Int, endTs: Int, chunkIds: [Int64]) -> Int64?
    func updateBatchStatus(batchId: Int64, status: String)
    func markBatchFailed(batchId: Int64, reason: String)

    // Record details about all LLM calls for a batch
    func updateBatchLLMMetadata(batchId: Int64, calls: [LLMCall])
    func fetchBatchLLMMetadata(batchId: Int64) -> [LLMCall]

    // Timeline‚Äëcards
    func saveTimelineCardShell(batchId: Int64, card: TimelineCardShell) -> Int64?
    func updateTimelineCardVideoURL(cardId: Int64, videoSummaryURL: String)
    func fetchTimelineCards(forBatch batchId: Int64) -> [TimelineCard]
    func fetchTimelineCard(byId id: Int64) -> TimelineCardWithTimestamps?

    // Timeline Queries
    func fetchTimelineCards(forDay day: String) -> [TimelineCard]
    func fetchTimelineCardsByTimeRange(from: Date, to: Date) -> [TimelineCard]
    func fetchTotalMinutesTrackedForWeek(containing date: Date) -> Double
    func replaceTimelineCardsInRange(from: Date, to: Date, with: [TimelineCardShell], batchId: Int64) -> (insertedIds: [Int64], deletedVideoPaths: [String])
    func fetchRecentTimelineCardsForDebug(limit: Int) -> [TimelineCardDebugEntry]

    func updateTimelineCardCategory(cardId: Int64, category: String)

    // Timeline review ratings (time-based)
    func fetchReviewRatingSegments(overlapping startTs: Int, endTs: Int) -> [TimelineReviewRatingSegment]
    func applyReviewRating(startTs: Int, endTs: Int, rating: String)
    func fetchUnreviewedTimelineCardCount(forDay day: String, coverageThreshold: Double) -> Int

    func fetchRecentLLMCallsForDebug(limit: Int) -> [LLMCallDebugEntry]
    func fetchRecentAnalysisBatchesForDebug(limit: Int) -> [AnalysisBatchDebugEntry]
    func fetchLLMCallsForBatches(batchIds: [Int64], limit: Int) -> [LLMCallDebugEntry]

    // Note: Transcript storage methods removed in favor of Observations
    
    // NEW: Observations Storage
    func saveObservations(batchId: Int64, observations: [Observation])
    func fetchObservations(batchId: Int64) -> [Observation]
    func fetchObservations(startTs: Int, endTs: Int) -> [Observation]
    func fetchObservationsByTimeRange(from: Date, to: Date) -> [Observation]

    // Helper for GeminiService ‚Äì map file paths ‚Üí timestamps
    func getTimestampsForVideoFiles(paths: [String]) -> [String: (startTs: Int, endTs: Int)]
    
    // Reprocessing Methods
    func deleteTimelineCards(forDay day: String) -> [String]  // Returns video paths to clean up
    func deleteTimelineCards(forBatchIds batchIds: [Int64]) -> [String]
    func deleteObservations(forBatchIds batchIds: [Int64])
    func resetBatchStatuses(forDay day: String) -> [Int64]  // Returns affected batch IDs
    func resetBatchStatuses(forBatchIds batchIds: [Int64]) -> [Int64]
    func fetchBatches(forDay day: String) -> [(id: Int64, startTs: Int, endTs: Int, status: String)]

    /// Chunks that belong to one batch, already sorted.
    func chunksForBatch(_ batchId: Int64) -> [RecordingChunk]

    /// All batches, newest first
    func allBatches() -> [(id: Int64, start: Int, end: Int, status: String)]

    // MARK: - Screenshot Management (new - replaces video chunks)

    /// Returns the next screenshot file URL (.jpg)
    func nextScreenshotURL() -> URL

    /// Save a screenshot to the database, returns the screenshot ID
    func saveScreenshot(url: URL, capturedAt: Date) -> Int64?

    /// Fetch screenshots that haven't been assigned to a batch yet
    func fetchUnprocessedScreenshots(since oldestTimestamp: Int) -> [Screenshot]

    /// Create a batch from screenshots, returns batch ID
    func saveBatchWithScreenshots(startTs: Int, endTs: Int, screenshotIds: [Int64]) -> Int64?

    /// Screenshots that belong to one batch, sorted by capture time
    func screenshotsForBatch(_ batchId: Int64) -> [Screenshot]

    /// Fetch screenshots within a time range (for timelapse generation)
    func fetchScreenshotsInTimeRange(startTs: Int, endTs: Int) -> [Screenshot]
}


// Journal entry for daily intentions, reflections, and AI summaries
struct JournalEntry: Codable, Sendable {
    var id: Int64?
    var day: String                    // "2025-01-15" format (4AM boundary)
    var intentions: String?            // Morning intentions
    var notes: String?                 // Additional notes
    var goals: String?                 // Long-term goals
    var reflections: String?           // Evening reflection
    var summary: String?               // AI-generated summary
    var status: String                 // "draft", "intentions_set", "complete"
    var createdAt: Date?
    var updatedAt: Date?

    init(
        id: Int64? = nil,
        day: String,
        intentions: String? = nil,
        notes: String? = nil,
        goals: String? = nil,
        reflections: String? = nil,
        summary: String? = nil,
        status: String = "draft",
        createdAt: Date? = nil,
        updatedAt: Date? = nil
    ) {
        self.id = id
        self.day = day
        self.intentions = intentions
        self.notes = notes
        self.goals = goals
        self.reflections = reflections
        self.summary = summary
        self.status = status
        self.createdAt = createdAt
        self.updatedAt = updatedAt
    }
}

// NEW: Observation struct for first-class transcript storage
struct Observation: Codable, Sendable {
    let id: Int64?
    let batchId: Int64
    let startTs: Int
    let endTs: Int
    let observation: String
    let metadata: String?
    let llmModel: String?
    let createdAt: Date?
}

// Re-add Distraction struct, as it's used by TimelineCard
struct Distraction: Codable, Sendable, Identifiable {
    let id: UUID
    let startTime: String
    let endTime: String
    let title: String
    let summary: String
    let videoSummaryURL: String? // Optional link to video summary for the distraction

    // Custom decoder to handle missing 'id'
    init(from decoder: Decoder) throws {
        let container = try decoder.container(keyedBy: CodingKeys.self)
        // Try to decode 'id', if not found or nil, assign a new UUID
        self.id = (try? container.decodeIfPresent(UUID.self, forKey: .id)) ?? UUID()
        self.startTime = try container.decode(String.self, forKey: .startTime)
        self.endTime = try container.decode(String.self, forKey: .endTime)
        self.title = try container.decode(String.self, forKey: .title)
        self.summary = try container.decode(String.self, forKey: .summary)
        self.videoSummaryURL = try container.decodeIfPresent(String.self, forKey: .videoSummaryURL)
    }

    // Add explicit init to maintain memberwise initializer if needed elsewhere,
    // though Codable synthesis might handle this. It's good practice.
    init(id: UUID = UUID(), startTime: String, endTime: String, title: String, summary: String, videoSummaryURL: String? = nil) {
        self.id = id
        self.startTime = startTime
        self.endTime = endTime
        self.title = title
        self.summary = summary
        self.videoSummaryURL = videoSummaryURL
    }

    // CodingKeys needed for custom decoder
    private enum CodingKeys: String, CodingKey {
        case id, startTime, endTime, title, summary, videoSummaryURL
    }
}

struct TimelineCard: Codable, Sendable, Identifiable {
    var id = UUID()
    let recordId: Int64?
    let batchId: Int64? // Tracks source batch for retry functionality
    let startTimestamp: String
    let endTimestamp: String
    let category: String
    let subcategory: String
    let title: String
    let summary: String
    let detailedSummary: String
    let day: String
    let distractions: [Distraction]?
    let videoSummaryURL: String? // Optional link to primary video summary
    let otherVideoSummaryURLs: [String]? // For merged cards, subsequent video URLs
    let appSites: AppSites?
    let isBackupGenerated: Bool?

    init(
        id: UUID = UUID(),
        recordId: Int64?,
        batchId: Int64?,
        startTimestamp: String,
        endTimestamp: String,
        category: String,
        subcategory: String,
        title: String,
        summary: String,
        detailedSummary: String,
        day: String,
        distractions: [Distraction]?,
        videoSummaryURL: String?,
        otherVideoSummaryURLs: [String]?,
        appSites: AppSites?,
        isBackupGenerated: Bool? = nil
    ) {
        self.id = id
        self.recordId = recordId
        self.batchId = batchId
        self.startTimestamp = startTimestamp
        self.endTimestamp = endTimestamp
        self.category = category
        self.subcategory = subcategory
        self.title = title
        self.summary = summary
        self.detailedSummary = detailedSummary
        self.day = day
        self.distractions = distractions
        self.videoSummaryURL = videoSummaryURL
        self.otherVideoSummaryURLs = otherVideoSummaryURLs
        self.appSites = appSites
        self.isBackupGenerated = isBackupGenerated
    }
}

/// Metadata about a single LLM request/response cycle
struct LLMCall: Codable, Sendable {
    let timestamp: Date?
    let latency: TimeInterval?
    let input: String?
    let output: String?
}

// DB record for llm_calls table
struct LLMCallDBRecord: Sendable {
    let batchId: Int64?
    let callGroupId: String?
    let attempt: Int
    let provider: String
    let model: String?
    let operation: String
    let status: String // "success" | "failure"
    let latencyMs: Int?
    let httpStatus: Int?
    let requestMethod: String?
    let requestURL: String?
    let requestHeadersJSON: String?
    let requestBody: String?
    let responseHeadersJSON: String?
    let responseBody: String?
    let errorDomain: String?
    let errorCode: Int?
    let errorMessage: String?
}

struct TimelineCardDebugEntry: Sendable {
    let createdAt: Date?
    let batchId: Int64?
    let day: String
    let startTime: String
    let endTime: String
    let category: String
    let subcategory: String?
    let title: String
    let summary: String?
    let detailedSummary: String?
}

struct TimelineReviewRatingSegment: Sendable {
    let id: Int64
    let startTs: Int
    let endTs: Int
    let rating: String
}

struct LLMCallDebugEntry: Sendable {
    let createdAt: Date?
    let batchId: Int64?
    let callGroupId: String?
    let attempt: Int
    let provider: String
    let model: String?
    let operation: String
    let status: String
    let latencyMs: Int?
    let httpStatus: Int?
    let requestMethod: String?
    let requestURL: String?
    let requestBody: String?
    let responseBody: String?
    let errorMessage: String?
}

// Add TimelineCardShell struct for the new save function
struct TimelineCardShell: Sendable {
    let startTimestamp: String
    let endTimestamp: String
    let category: String
    let subcategory: String
    let title: String
    let summary: String
    let detailedSummary: String
    let distractions: [Distraction]? // Keep this, it's part of the initial save
    let appSites: AppSites?
    let isBackupGenerated: Bool?
    // No videoSummaryURL here, as it's added later
    // No batchId here, as it's passed as a separate parameter to the save function

    init(
        startTimestamp: String,
        endTimestamp: String,
        category: String,
        subcategory: String,
        title: String,
        summary: String,
        detailedSummary: String,
        distractions: [Distraction]?,
        appSites: AppSites?,
        isBackupGenerated: Bool? = nil
    ) {
        self.startTimestamp = startTimestamp
        self.endTimestamp = endTimestamp
        self.category = category
        self.subcategory = subcategory
        self.title = title
        self.summary = summary
        self.detailedSummary = detailedSummary
        self.distractions = distractions
        self.appSites = appSites
        self.isBackupGenerated = isBackupGenerated
    }
}

// New metadata envelope to support multiple fields under one JSON column
private struct TimelineMetadata: Codable {
    let distractions: [Distraction]?
    let appSites: AppSites?
    let isBackupGenerated: Bool?
}

struct AnalysisBatchDebugEntry: Sendable {
    let id: Int64
    let status: String
    let startTs: Int
    let endTs: Int
    let createdAt: Date?
    let reason: String?
}

// Extended TimelineCard with timestamp fields for internal use
struct TimelineCardWithTimestamps {
    let id: Int64
    let startTimestamp: String
    let endTimestamp: String
    let startTs: Int
    let endTs: Int
    let category: String
    let subcategory: String
    let title: String
    let summary: String
    let detailedSummary: String
    let day: String
    let distractions: [Distraction]?
    let videoSummaryURL: String?
}


final class StorageManager: StorageManaging, @unchecked Sendable {
    static let shared = StorageManager()

    private let dbURL: URL
    private var db: DatabasePool!  // var to allow recovery reassignment
    private let fileMgr = FileManager.default
    private let root: URL
    private let backupsDir: URL
    var recordingsRoot: URL { root }

    // TEMPORARY DEBUG: Remove after identifying slow queries
    private let debugSlowQueries = true
    private let slowThresholdMs: Double = 100  // Log anything over 100ms

    // Dedicated queue for database writes to prevent main thread blocking
    private let dbWriteQueue = DispatchQueue(label: "com.dayflow.storage.writes", qos: .utility)

    private init() {
        UserDefaultsMigrator.migrateIfNeeded()
        StoragePathMigrator.migrateIfNeeded()

        let appSupport = fileMgr.urls(for: .applicationSupportDirectory, in: .userDomainMask)[0]
        let baseDir = appSupport.appendingPathComponent("Dayflow", isDirectory: true)
        let recordingsDir = baseDir.appendingPathComponent("recordings", isDirectory: true)
        let backupDir = baseDir.appendingPathComponent("backups", isDirectory: true)

        // Ensure directories exist before opening database
        try? fileMgr.createDirectory(at: baseDir, withIntermediateDirectories: true)
        try? fileMgr.createDirectory(at: recordingsDir, withIntermediateDirectories: true)
        try? fileMgr.createDirectory(at: backupDir, withIntermediateDirectories: true)

        root = recordingsDir
        backupsDir = backupDir
        dbURL = baseDir.appendingPathComponent("chunks.sqlite")

        StorageManager.migrateDatabaseLocationIfNeeded(
            fileManager: fileMgr,
            legacyRecordingsDir: recordingsDir,
            newDatabaseURL: dbURL
        )

        // Configure database with WAL mode for better performance and safety
        var config = Configuration()
        config.maximumReaderCount = 5
        config.prepareDatabase { db in
            if !db.configuration.readonly {
                try db.execute(sql: "PRAGMA journal_mode = WAL")
                try db.execute(sql: "PRAGMA synchronous = NORMAL")
            }
            try db.execute(sql: "PRAGMA busy_timeout = 5000")
        }

        // Safe database initialization with automatic recovery from backup
        db = Self.openDatabaseSafely(
            at: dbURL,
            backupsDir: backupDir,
            config: config,
            fileManager: fileMgr
        )

        // TEMPORARY DEBUG: SQL statement tracing (via configuration)
        #if DEBUG
        try? db.write { db in
            db.trace { event in
                if case .profile(let statement, let duration) = event, duration > 0.1 {
                    print("üìä SLOW SQL (\(Int(duration * 1000))ms): \(statement)")
                }
            }
        }
        #endif

        // Run integrity check on launch (logs warning if issues found)
        performIntegrityCheck()

        migrate()
        migrateLegacyChunkPathsIfNeeded()

        // Run initial purge, then schedule hourly
        purgeIfNeeded()
        TimelapseStorageManager.shared.purgeIfNeeded()
        startPurgeScheduler()

        // Schedule WAL checkpoints every 5 minutes to prevent data loss
        startCheckpointScheduler()

        // Schedule daily backups
        startBackupScheduler()
    }

    // TEMPORARY DEBUG: Timing helpers for database operations
    private func timedWrite<T>(_ label: String, _ block: (Database) throws -> T) throws -> T {
        let callStart = CFAbsoluteTimeGetCurrent()
        var execStart: CFAbsoluteTime = 0
        var execEnd: CFAbsoluteTime = 0

        let writeBreadcrumb = Breadcrumb(level: .debug, category: "database")
        writeBreadcrumb.message = "DB write: \(label)"
        writeBreadcrumb.type = "debug"
        SentryHelper.addBreadcrumb(writeBreadcrumb)

        do {
            let result = try db.write { db in
                execStart = CFAbsoluteTimeGetCurrent()
                defer { execEnd = CFAbsoluteTimeGetCurrent() }
                return try block(db)
            }

            let waitMs = max(0, (execStart - callStart) * 1000)
            let execMs = max(0, (execEnd - execStart) * 1000)

            if debugSlowQueries && (execMs > slowThresholdMs || waitMs > slowThresholdMs) {
                print("‚ö†Ô∏è SLOW WRITE [\(label)]: wait=\(Int(waitMs))ms exec=\(Int(execMs))ms")

                let slowWriteBreadcrumb = Breadcrumb(level: .warning, category: "database")
                slowWriteBreadcrumb.message = "SLOW DB write: \(label)"
                slowWriteBreadcrumb.data = [
                    "duration_ms": Int((waitMs + execMs).rounded()),
                    "wait_ms": Int(waitMs.rounded()),
                    "exec_ms": Int(execMs.rounded())
                ]
                slowWriteBreadcrumb.type = "error"
                SentryHelper.addBreadcrumb(slowWriteBreadcrumb)
            }

            return result
        } catch {
            if execStart == 0 {
                execStart = CFAbsoluteTimeGetCurrent()
            }
            if execEnd == 0 {
                execEnd = CFAbsoluteTimeGetCurrent()
            }
            let waitMs = max(0, (execStart - callStart) * 1000)
            let execMs = max(0, (execEnd - execStart) * 1000)

            let slowWriteBreadcrumb = Breadcrumb(level: .error, category: "database")
            slowWriteBreadcrumb.message = "FAILED DB write: \(label)"
            slowWriteBreadcrumb.data = [
                "wait_ms": Int(waitMs.rounded()),
                "exec_ms": Int(execMs.rounded()),
                "error": "\(error)"
            ]
            slowWriteBreadcrumb.type = "error"
            SentryHelper.addBreadcrumb(slowWriteBreadcrumb)
            throw error
        }
    }

    private func timedRead<T>(_ label: String, _ block: (Database) throws -> T) throws -> T {
        let callStart = CFAbsoluteTimeGetCurrent()
        var execStart: CFAbsoluteTime = 0
        var execEnd: CFAbsoluteTime = 0

        let readBreadcrumb = Breadcrumb(level: .debug, category: "database")
        readBreadcrumb.message = "DB read: \(label)"
        readBreadcrumb.type = "debug"
        SentryHelper.addBreadcrumb(readBreadcrumb)

        do {
            let result = try db.read { db in
                execStart = CFAbsoluteTimeGetCurrent()
                defer { execEnd = CFAbsoluteTimeGetCurrent() }
                return try block(db)
            }

            let waitMs = max(0, (execStart - callStart) * 1000)
            let execMs = max(0, (execEnd - execStart) * 1000)

            if debugSlowQueries && (execMs > slowThresholdMs || waitMs > slowThresholdMs) {
                print("‚ö†Ô∏è SLOW READ [\(label)]: wait=\(Int(waitMs))ms exec=\(Int(execMs))ms")

                let slowReadBreadcrumb = Breadcrumb(level: .warning, category: "database")
                slowReadBreadcrumb.message = "SLOW DB read: \(label)"
                slowReadBreadcrumb.data = [
                    "duration_ms": Int((waitMs + execMs).rounded()),
                    "wait_ms": Int(waitMs.rounded()),
                    "exec_ms": Int(execMs.rounded())
                ]
                slowReadBreadcrumb.type = "error"
                SentryHelper.addBreadcrumb(slowReadBreadcrumb)
            }

            return result
        } catch {
            if execStart == 0 {
                execStart = CFAbsoluteTimeGetCurrent()
            }
            if execEnd == 0 {
                execEnd = CFAbsoluteTimeGetCurrent()
            }
            let waitMs = max(0, (execStart - callStart) * 1000)
            let execMs = max(0, (execEnd - execStart) * 1000)

            let slowReadBreadcrumb = Breadcrumb(level: .error, category: "database")
            slowReadBreadcrumb.message = "FAILED DB read: \(label)"
            slowReadBreadcrumb.data = [
                "wait_ms": Int(waitMs.rounded()),
                "exec_ms": Int(execMs.rounded()),
                "error": "\(error)"
            ]
            slowReadBreadcrumb.type = "error"
            SentryHelper.addBreadcrumb(slowReadBreadcrumb)
            throw error
        }
    }

    private func migrate() {
        try? timedWrite("migrate") { db in
            // Create all tables with their final schema
            try db.execute(sql: """
                -- Chunks table: stores video recording segments
                CREATE TABLE IF NOT EXISTS chunks (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    start_ts INTEGER NOT NULL,
                    end_ts INTEGER NOT NULL,
                    file_url TEXT NOT NULL,
                    status TEXT NOT NULL DEFAULT 'recording',
                    is_deleted INTEGER DEFAULT 0
                );
                CREATE INDEX IF NOT EXISTS idx_chunks_status ON chunks(status);
                CREATE INDEX IF NOT EXISTS idx_chunks_start_ts ON chunks(start_ts);
                CREATE INDEX IF NOT EXISTS idx_chunks_status_start_ts ON chunks(status, start_ts);
                
                -- Analysis batches: groups chunks for LLM processing
                CREATE TABLE IF NOT EXISTS analysis_batches (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    batch_start_ts INTEGER NOT NULL,
                    batch_end_ts INTEGER NOT NULL,
                    status TEXT NOT NULL DEFAULT 'pending',
                    reason TEXT,
                    llm_metadata TEXT,
                    detailed_transcription TEXT,
                    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_analysis_batches_status ON analysis_batches(status);
                
                -- Junction table linking batches to chunks
                CREATE TABLE IF NOT EXISTS batch_chunks (
                    batch_id INTEGER NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
                    chunk_id INTEGER NOT NULL REFERENCES chunks(id) ON DELETE RESTRICT,
                    PRIMARY KEY (batch_id, chunk_id)
                );
                CREATE INDEX IF NOT EXISTS idx_batch_chunks_chunk ON batch_chunks(chunk_id);
                
                -- Timeline cards: stores activity summaries
                CREATE TABLE IF NOT EXISTS timeline_cards (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    batch_id INTEGER REFERENCES analysis_batches(id) ON DELETE CASCADE,
                    start TEXT NOT NULL,       -- Clock time (e.g., "2:30 PM")
                    end TEXT NOT NULL,         -- Clock time (e.g., "3:45 PM")
                    start_ts INTEGER,          -- Unix timestamp
                    end_ts INTEGER,            -- Unix timestamp
                    day DATE NOT NULL,
                    title TEXT NOT NULL,
                    summary TEXT,
                    category TEXT NOT NULL,
                    subcategory TEXT,
                    detailed_summary TEXT,
                    metadata TEXT,             -- For distractions JSON
                    video_summary_url TEXT,    -- Link to video summary on filesystem
                    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_timeline_cards_day ON timeline_cards(day);
                CREATE INDEX IF NOT EXISTS idx_timeline_cards_start_ts ON timeline_cards(start_ts);
                CREATE INDEX IF NOT EXISTS idx_timeline_cards_time_range ON timeline_cards(start_ts, end_ts);

                -- Timeline review ratings: stores time-based review segments
                CREATE TABLE IF NOT EXISTS timeline_review_ratings (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    start_ts INTEGER NOT NULL,
                    end_ts INTEGER NOT NULL,
                    rating TEXT NOT NULL
                );
                CREATE INDEX IF NOT EXISTS idx_review_ratings_time ON timeline_review_ratings(start_ts, end_ts);
                
                -- Observations: stores LLM transcription outputs
                CREATE TABLE IF NOT EXISTS observations (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    batch_id INTEGER NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
                    start_ts INTEGER NOT NULL,
                    end_ts INTEGER NOT NULL,
                    observation TEXT NOT NULL,
                    metadata TEXT,
                    llm_model TEXT,
                    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_observations_batch_id ON observations(batch_id);
                CREATE INDEX IF NOT EXISTS idx_observations_start_ts ON observations(start_ts);
                CREATE INDEX IF NOT EXISTS idx_observations_time_range ON observations(start_ts, end_ts);

                -- Screenshots table: stores periodic screen captures (replaces video chunks)
                CREATE TABLE IF NOT EXISTS screenshots (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    captured_at INTEGER NOT NULL,
                    file_path TEXT NOT NULL,
                    file_size INTEGER,
                    is_deleted INTEGER DEFAULT 0,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_screenshots_captured_at ON screenshots(captured_at);

                -- Junction table linking batches to screenshots
                CREATE TABLE IF NOT EXISTS batch_screenshots (
                    batch_id INTEGER NOT NULL REFERENCES analysis_batches(id) ON DELETE CASCADE,
                    screenshot_id INTEGER NOT NULL REFERENCES screenshots(id) ON DELETE RESTRICT,
                    PRIMARY KEY (batch_id, screenshot_id)
                );
                CREATE INDEX IF NOT EXISTS idx_batch_screenshots_screenshot ON batch_screenshots(screenshot_id);
            """)

            // Journal entries table: stores daily intentions, reflections, and summaries
            try db.execute(sql: """
                CREATE TABLE IF NOT EXISTS journal_entries (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    day TEXT NOT NULL UNIQUE,
                    intentions TEXT,
                    notes TEXT,
                    goals TEXT,
                    reflections TEXT,
                    summary TEXT,
                    status TEXT NOT NULL DEFAULT 'draft',
                    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP
                );
                CREATE INDEX IF NOT EXISTS idx_journal_entries_day ON journal_entries(day);
                CREATE INDEX IF NOT EXISTS idx_journal_entries_status ON journal_entries(status);
            """)

            // LLM calls logging table
            try db.execute(sql: """
                CREATE TABLE IF NOT EXISTS llm_calls (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    batch_id INTEGER NULL,
                    call_group_id TEXT NULL,
                    attempt INTEGER NOT NULL DEFAULT 1,
                    provider TEXT NOT NULL,
                    model TEXT NULL,
                    operation TEXT NOT NULL,
                    status TEXT NOT NULL CHECK(status IN ('success','failure')),
                    latency_ms INTEGER NULL,
                    http_status INTEGER NULL,
                    request_method TEXT NULL,
                    request_url TEXT NULL,
                    request_headers TEXT NULL,
                    request_body TEXT NULL,
                    response_headers TEXT NULL,
                    response_body TEXT NULL,
                    error_domain TEXT NULL,
                    error_code INTEGER NULL,
                    error_message TEXT NULL
                );
                CREATE INDEX IF NOT EXISTS idx_llm_calls_created ON llm_calls(created_at DESC);
                CREATE INDEX IF NOT EXISTS idx_llm_calls_group ON llm_calls(call_group_id, attempt);
                CREATE INDEX IF NOT EXISTS idx_llm_calls_batch ON llm_calls(batch_id);
            """)

            // Screenshot context: app info captured at screenshot time (for search feature)
            try db.execute(sql: """
                CREATE TABLE IF NOT EXISTS screenshot_context (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    screenshot_id INTEGER NOT NULL REFERENCES screenshots(id) ON DELETE CASCADE,
                    app_name TEXT,
                    bundle_id TEXT,
                    window_title TEXT,
                    browser_url TEXT,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(screenshot_id)
                );
                CREATE INDEX IF NOT EXISTS idx_screenshot_context_screenshot ON screenshot_context(screenshot_id);
                CREATE INDEX IF NOT EXISTS idx_screenshot_context_app ON screenshot_context(bundle_id);
            """)

            // Screenshot OCR: text extracted from screenshots (for search feature)
            try db.execute(sql: """
                CREATE TABLE IF NOT EXISTS screenshot_ocr (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    screenshot_id INTEGER NOT NULL REFERENCES screenshots(id) ON DELETE CASCADE,
                    ocr_text TEXT NOT NULL,
                    ocr_regions TEXT,
                    confidence REAL,
                    processing_duration_ms INTEGER,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(screenshot_id)
                );
                CREATE INDEX IF NOT EXISTS idx_screenshot_ocr_screenshot ON screenshot_ocr(screenshot_id);
            """)

            // FTS5 virtual table for full-text search across screenshots
            try db.execute(sql: """
                CREATE VIRTUAL TABLE IF NOT EXISTS screenshot_search USING fts5(
                    ocr_text,
                    window_title,
                    app_name,
                    browser_url,
                    content='',
                    content_rowid='id'
                );
            """)

            // Migration: Add soft delete column to timeline_cards if it doesn't exist
            let timelineCardsColumns = try db.columns(in: "timeline_cards").map { $0.name }
            if !timelineCardsColumns.contains("is_deleted") {
                try db.execute(sql: """
                    ALTER TABLE timeline_cards ADD COLUMN is_deleted INTEGER NOT NULL DEFAULT 0;
                """)

                // Create composite partial indexes for common query patterns
                try db.execute(sql: """
                    CREATE INDEX IF NOT EXISTS idx_timeline_cards_active_start_ts
                    ON timeline_cards(start_ts)
                    WHERE is_deleted = 0;
                """)

                try db.execute(sql: """
                    CREATE INDEX IF NOT EXISTS idx_timeline_cards_active_batch
                    ON timeline_cards(batch_id)
                    WHERE is_deleted = 0;
                """)

                print("‚úÖ Added is_deleted column and composite indexes to timeline_cards")
            }
        }
    }


    func nextFileURL() -> URL {
        let df = DateFormatter(); df.dateFormat = "yyyyMMdd_HHmmssSSS"
        return root.appendingPathComponent("\(df.string(from: Date())).mp4")
    }

    func registerChunk(url: URL) {
        let ts = Int(Date().timeIntervalSince1970)
        let path = url.path

        // Perform database write asynchronously to avoid blocking caller thread
        dbWriteQueue.async { [weak self] in
            try? self?.timedWrite("registerChunk") { db in
                try db.execute(sql: "INSERT INTO chunks(start_ts, end_ts, file_url, status) VALUES (?, ?, ?, 'recording')",
                               arguments: [ts, ts + 60, path])
            }
        }
    }

    func markChunkCompleted(url: URL) {
        let end = Int(Date().timeIntervalSince1970)
        let path = url.path

        // Perform database write asynchronously to avoid blocking caller thread
        dbWriteQueue.async { [weak self] in
            try? self?.timedWrite("markChunkCompleted") { db in
                try db.execute(sql: "UPDATE chunks SET end_ts = ?, status = 'completed' WHERE file_url = ?",
                               arguments: [end, path])
            }
        }
    }

    func markChunkFailed(url: URL) {
        let path = url.path

        // Perform database write and file deletion asynchronously to avoid blocking caller thread
        dbWriteQueue.async { [weak self] in
            guard let self = self else { return }

            try? self.timedWrite("markChunkFailed") { db in
                try db.execute(sql: "DELETE FROM chunks WHERE file_url = ?", arguments: [path])
            }

            try? self.fileMgr.removeItem(at: url)
        }
    }


    func fetchUnprocessedChunks(olderThan oldestAllowed: Int) -> [RecordingChunk] {
        (try? timedRead("fetchUnprocessedChunks") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM chunks
                WHERE start_ts >= ?
                  AND status = 'completed'
                  AND (is_deleted = 0 OR is_deleted IS NULL)
                  AND id NOT IN (SELECT chunk_id FROM batch_chunks)
                ORDER BY start_ts ASC
            """, arguments: [oldestAllowed])
                .map { row in
                    RecordingChunk(id: row["id"], startTs: row["start_ts"], endTs: row["end_ts"], fileUrl: row["file_url"], status: row["status"]) }
        }) ?? []
    }

    func saveBatch(startTs: Int, endTs: Int, chunkIds: [Int64]) -> Int64? {
        guard !chunkIds.isEmpty else { return nil }
        var batchID: Int64 = 0
        try? timedWrite("saveBatch(\(chunkIds.count)_chunks)") { db in
            try db.execute(sql: "INSERT INTO analysis_batches(batch_start_ts, batch_end_ts) VALUES (?, ?)",
                           arguments: [startTs, endTs])
            batchID = db.lastInsertedRowID
            for id in chunkIds {
                try db.execute(sql: "INSERT INTO batch_chunks(batch_id, chunk_id) VALUES (?, ?)", arguments: [batchID, id])
            }
        }
        return batchID == 0 ? nil : batchID
    }

    func updateBatchStatus(batchId: Int64, status: String) {
        // Perform database write asynchronously to avoid blocking caller thread
        dbWriteQueue.async { [weak self] in
            try? self?.timedWrite("updateBatchStatus") { db in
                try db.execute(sql: "UPDATE analysis_batches SET status = ? WHERE id = ?", arguments: [status, batchId])
            }
        }
    }

    func markBatchFailed(batchId: Int64, reason: String) {
        // Perform database write asynchronously to avoid blocking caller thread
        dbWriteQueue.async { [weak self] in
            try? self?.timedWrite("markBatchFailed") { db in
                try db.execute(sql: "UPDATE analysis_batches SET status = 'failed', reason = ? WHERE id = ?", arguments: [reason, batchId])
            }
        }
    }

    func updateBatchLLMMetadata(batchId: Int64, calls: [LLMCall]) {
        let encoder = JSONEncoder()
        encoder.dateEncodingStrategy = .iso8601
        guard let data = try? encoder.encode(calls), let json = String(data: data, encoding: .utf8) else { return }
        try? timedWrite("updateBatchLLMMetadata") { db in
            try db.execute(sql: "UPDATE analysis_batches SET llm_metadata = ? WHERE id = ?", arguments: [json, batchId])
        }
    }

    func fetchBatchLLMMetadata(batchId: Int64) -> [LLMCall] {
        let decoder = JSONDecoder()
        decoder.dateDecodingStrategy = .iso8601
        return (try? timedRead("fetchBatchLLMMetadata") { db in
            if let row = try Row.fetchOne(db, sql: "SELECT llm_metadata FROM analysis_batches WHERE id = ?", arguments: [batchId]),
               let json: String = row["llm_metadata"],
               let data = json.data(using: .utf8) {
                return try decoder.decode([LLMCall].self, from: data)
            }
            return []
        }) ?? []
    }

    /// Chunks that belong to one batch, already sorted.
    func chunksForBatch(_ batchId: Int64) -> [RecordingChunk] {
        (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT c.* FROM batch_chunks bc
                JOIN chunks c ON c.id = bc.chunk_id
                WHERE bc.batch_id = ?
                  AND (c.is_deleted = 0 OR c.is_deleted IS NULL)
                ORDER BY c.start_ts ASC
                """, arguments: [batchId]
            ).map { r in
                RecordingChunk(id: r["id"], startTs: r["start_ts"], endTs: r["end_ts"],
                               fileUrl: r["file_url"], status: r["status"])
            }
        }) ?? []
    }

    /// Helper to get the batch start timestamp for date calculations
    private func getBatchStartTimestamp(batchId: Int64) -> Int? {
        return try? db.read { db in
            try Int.fetchOne(db, sql: """
                SELECT batch_start_ts FROM analysis_batches WHERE id = ?
            """, arguments: [batchId])
        }
    }
    
    /// Fetch chunks that overlap with a specific time range
    func fetchChunksInTimeRange(startTs: Int, endTs: Int) -> [RecordingChunk] {
        (try? timedRead("fetchChunksInTimeRange") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM chunks
                WHERE status = 'completed'
                  AND (is_deleted = 0 OR is_deleted IS NULL)
                  AND ((start_ts <= ? AND end_ts >= ?)
                       OR (start_ts >= ? AND start_ts <= ?)
                       OR (end_ts >= ? AND end_ts <= ?))
                ORDER BY start_ts ASC
            """, arguments: [endTs, startTs, startTs, endTs, startTs, endTs])
            .map { r in
                RecordingChunk(id: r["id"], startTs: r["start_ts"], endTs: r["end_ts"],
                              fileUrl: r["file_url"], status: r["status"])
            }
        }) ?? []
    }

    // MARK: - Screenshot Management (new - replaces video chunks)

    func nextScreenshotURL() -> URL {
        let df = DateFormatter()
        df.dateFormat = "yyyyMMdd_HHmmssSSS"
        return root.appendingPathComponent("\(df.string(from: Date())).jpg")
    }

    func saveScreenshot(url: URL, capturedAt: Date) -> Int64? {
        let timestamp = Int(capturedAt.timeIntervalSince1970)
        let path = url.path
        let fileSize: Int64? = {
            if let attrs = try? fileMgr.attributesOfItem(atPath: path),
               let size = attrs[.size] as? NSNumber {
                return size.int64Value
            }
            return nil
        }()

        var screenshotId: Int64?
        try? timedWrite("saveScreenshot") { db in
            try db.execute(sql: """
                INSERT INTO screenshots(captured_at, file_path, file_size)
                VALUES (?, ?, ?)
            """, arguments: [timestamp, path, fileSize])
            screenshotId = db.lastInsertedRowID
        }
        return screenshotId
    }

    /// Save app context captured at screenshot time (for search feature)
    func saveScreenshotContext(screenshotId: Int64, appName: String?, bundleId: String?, windowTitle: String?, browserURL: String?) {
        try? timedWrite("saveScreenshotContext") { db in
            try db.execute(sql: """
                INSERT INTO screenshot_context(screenshot_id, app_name, bundle_id, window_title, browser_url)
                VALUES (?, ?, ?, ?, ?)
            """, arguments: [screenshotId, appName, bundleId, windowTitle, browserURL])
        }
    }

    // MARK: - OCR Storage (for search feature)

    /// Fetch screenshots that haven't been OCR processed yet
    func fetchScreenshotsWithoutOCR(limit: Int) -> [(screenshotId: Int64, filePath: String)] {
        (try? timedRead("fetchScreenshotsWithoutOCR") { db in
            try Row.fetchAll(db, sql: """
                SELECT s.id, s.file_path FROM screenshots s
                LEFT JOIN screenshot_ocr o ON s.id = o.screenshot_id
                WHERE o.id IS NULL
                  AND s.is_deleted = 0
                ORDER BY s.captured_at DESC
                LIMIT ?
            """, arguments: [limit])
            .compactMap { row -> (Int64, String)? in
                guard let id: Int64 = row["id"],
                      let path: String = row["file_path"] else { return nil }
                return (id, path)
            }
        }) ?? []
    }

    /// Save OCR results for a screenshot
    func saveScreenshotOCR(screenshotId: Int64, ocrText: String, ocrRegions: [OCRProcessingService.TextRegion], confidence: Float, processingDurationMs: Int) {
        let regionsJSON: String? = {
            guard !ocrRegions.isEmpty else { return nil }
            let encoder = JSONEncoder()
            if let data = try? encoder.encode(ocrRegions) {
                return String(data: data, encoding: .utf8)
            }
            return nil
        }()

        try? timedWrite("saveScreenshotOCR") { db in
            try db.execute(sql: """
                INSERT INTO screenshot_ocr(screenshot_id, ocr_text, ocr_regions, confidence, processing_duration_ms)
                VALUES (?, ?, ?, ?, ?)
            """, arguments: [screenshotId, ocrText, regionsJSON, confidence, processingDurationMs])

            // Also update FTS index
            // First get context data for this screenshot
            if let contextRow = try? Row.fetchOne(db, sql: """
                SELECT app_name, window_title, browser_url FROM screenshot_context
                WHERE screenshot_id = ?
            """, arguments: [screenshotId]) {
                let appName: String? = contextRow["app_name"]
                let windowTitle: String? = contextRow["window_title"]
                let browserURL: String? = contextRow["browser_url"]

                try db.execute(sql: """
                    INSERT INTO screenshot_search(rowid, ocr_text, window_title, app_name, browser_url)
                    VALUES (?, ?, ?, ?, ?)
                """, arguments: [screenshotId, ocrText, windowTitle, appName, browserURL])
            } else {
                // No context, just index OCR text
                try db.execute(sql: """
                    INSERT INTO screenshot_search(rowid, ocr_text, window_title, app_name, browser_url)
                    VALUES (?, ?, NULL, NULL, NULL)
                """, arguments: [screenshotId, ocrText])
            }
        }
    }

    // MARK: - Search (for search feature)

    /// Search screenshots using FTS5 full-text search
    func searchScreenshots(ftsQuery: String, filters: SearchService.SearchFilters?, limit: Int, offset: Int) -> [SearchService.SearchResult] {
        (try? timedRead("searchScreenshots") { db in
            // Build SQL with optional filters
            var conditions: [String] = []
            var arguments: [DatabaseValueConvertible] = []

            // Date range filter
            if let dateRange = filters?.dateRange {
                let startTs = Int(dateRange.lowerBound.timeIntervalSince1970)
                let endTs = Int(dateRange.upperBound.timeIntervalSince1970)
                conditions.append("s.captured_at >= ? AND s.captured_at <= ?")
                arguments.append(contentsOf: [startTs, endTs])
            }

            // App filter
            if let bundleIds = filters?.appBundleIds, !bundleIds.isEmpty {
                let placeholders = bundleIds.map { _ in "?" }.joined(separator: ", ")
                conditions.append("c.bundle_id IN (\(placeholders))")
                arguments.append(contentsOf: bundleIds)
            }

            let whereClause = conditions.isEmpty ? "" : " AND " + conditions.joined(separator: " AND ")

            // FTS query with snippet for match highlighting
            arguments.insert(ftsQuery, at: 0)

            // Note: FTS5 table is contentless so snippet() won't work
            // Instead, get OCR text directly and truncate
            let sql = """
                SELECT
                    s.id,
                    s.file_path,
                    s.captured_at,
                    substr(o.ocr_text, 1, 200) AS matched_text,
                    c.app_name,
                    c.window_title,
                    c.bundle_id,
                    c.browser_url,
                    o.ocr_regions
                FROM screenshot_search fts
                JOIN screenshots s ON s.id = fts.rowid
                LEFT JOIN screenshot_ocr o ON o.screenshot_id = s.id
                LEFT JOIN screenshot_context c ON c.screenshot_id = s.id
                WHERE screenshot_search MATCH ?
                  AND s.is_deleted = 0
                \(whereClause)
                ORDER BY fts.rank, s.captured_at DESC
                LIMIT ? OFFSET ?
            """

            arguments.append(limit)
            arguments.append(offset)

            return try Row.fetchAll(db, sql: sql, arguments: StatementArguments(arguments))
                .map { row in
                    // Parse OCR regions from JSON
                    var ocrRegions: [SearchService.TextRegion] = []
                    if let regionsJson = row["ocr_regions"] as? String,
                       let data = regionsJson.data(using: .utf8) {
                        ocrRegions = (try? JSONDecoder().decode([SearchService.TextRegion].self, from: data)) ?? []
                    }

                    return SearchService.SearchResult(
                        id: row["id"] ?? 0,
                        screenshotPath: row["file_path"] ?? "",
                        capturedAt: Date(timeIntervalSince1970: TimeInterval(row["captured_at"] as Int? ?? 0)),
                        matchedText: row["matched_text"] ?? "",
                        appName: row["app_name"],
                        windowTitle: row["window_title"],
                        bundleId: row["bundle_id"],
                        browserURL: row["browser_url"],
                        ocrRegions: ocrRegions
                    )
                }
        }) ?? []
    }

    /// Fetch distinct apps for filter dropdown
    func fetchDistinctApps() -> [SearchService.AppInfo] {
        (try? timedRead("fetchDistinctApps") { db in
            try Row.fetchAll(db, sql: """
                SELECT c.app_name, c.bundle_id, COUNT(*) as count
                FROM screenshot_context c
                JOIN screenshots s ON s.id = c.screenshot_id
                WHERE s.is_deleted = 0
                  AND c.bundle_id IS NOT NULL
                GROUP BY c.bundle_id
                ORDER BY count DESC
            """)
            .compactMap { row -> SearchService.AppInfo? in
                guard let name: String = row["app_name"],
                      let bundleId: String = row["bundle_id"],
                      let count: Int = row["count"] else { return nil }
                return SearchService.AppInfo(name: name, bundleId: bundleId, count: count)
            }
        }) ?? []
    }

    func fetchUnprocessedScreenshots(since oldestTimestamp: Int) -> [Screenshot] {
        (try? timedRead("fetchUnprocessedScreenshots") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM screenshots
                WHERE captured_at >= ?
                  AND is_deleted = 0
                  AND id NOT IN (SELECT screenshot_id FROM batch_screenshots)
                ORDER BY captured_at ASC
            """, arguments: [oldestTimestamp])
            .map { row in
                Screenshot(
                    id: row["id"],
                    capturedAt: row["captured_at"],
                    filePath: row["file_path"],
                    fileSize: row["file_size"],
                    isDeleted: (row["is_deleted"] as? Int ?? 0) != 0
                )
            }
        }) ?? []
    }

    func saveBatchWithScreenshots(startTs: Int, endTs: Int, screenshotIds: [Int64]) -> Int64? {
        guard !screenshotIds.isEmpty else { return nil }
        var batchId: Int64 = 0

        try? timedWrite("saveBatchWithScreenshots(\(screenshotIds.count))") { db in
            try db.execute(sql: """
                INSERT INTO analysis_batches(batch_start_ts, batch_end_ts)
                VALUES (?, ?)
            """, arguments: [startTs, endTs])
            batchId = db.lastInsertedRowID

            for id in screenshotIds {
                try db.execute(sql: """
                    INSERT INTO batch_screenshots(batch_id, screenshot_id)
                    VALUES (?, ?)
                """, arguments: [batchId, id])
            }
        }
        return batchId == 0 ? nil : batchId
    }

    func screenshotsForBatch(_ batchId: Int64) -> [Screenshot] {
        (try? timedRead("screenshotsForBatch") { db in
            try Row.fetchAll(db, sql: """
                SELECT s.* FROM batch_screenshots bs
                JOIN screenshots s ON s.id = bs.screenshot_id
                WHERE bs.batch_id = ?
                  AND s.is_deleted = 0
                ORDER BY s.captured_at ASC
            """, arguments: [batchId])
            .map { row in
                Screenshot(
                    id: row["id"],
                    capturedAt: row["captured_at"],
                    filePath: row["file_path"],
                    fileSize: row["file_size"],
                    isDeleted: (row["is_deleted"] as? Int ?? 0) != 0
                )
            }
        }) ?? []
    }

    func fetchScreenshotsInTimeRange(startTs: Int, endTs: Int) -> [Screenshot] {
        (try? timedRead("fetchScreenshotsInTimeRange") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM screenshots
                WHERE captured_at >= ? AND captured_at <= ?
                  AND is_deleted = 0
                ORDER BY captured_at ASC
            """, arguments: [startTs, endTs])
            .map { row in
                Screenshot(
                    id: row["id"],
                    capturedAt: row["captured_at"],
                    filePath: row["file_path"],
                    fileSize: row["file_size"],
                    isDeleted: (row["is_deleted"] as? Int ?? 0) != 0
                )
            }
        }) ?? []
    }

    func saveTimelineCardShell(batchId: Int64, card: TimelineCardShell) -> Int64? {
        let encoder = JSONEncoder()
        var lastId: Int64? = nil

        // Get the batch's actual start timestamp to use as the base date
        guard let batchStartTs = getBatchStartTimestamp(batchId: batchId) else {
            return nil
        }
        let baseDate = Date(timeIntervalSince1970: TimeInterval(batchStartTs))

        let timeFormatter = DateFormatter()
        timeFormatter.dateFormat = "h:mm a"
        timeFormatter.locale = Locale(identifier: "en_US_POSIX")

        guard let startTime = timeFormatter.date(from: card.startTimestamp),
              let endTime = timeFormatter.date(from: card.endTimestamp) else {
            return nil
        }

        let calendar = Calendar.current

        let startComponents = calendar.dateComponents([.hour, .minute], from: startTime)
        guard let startHour = startComponents.hour, let startMinute = startComponents.minute else { return nil }

        var startDate = calendar.date(bySettingHour: startHour, minute: startMinute, second: 0, of: baseDate) ?? baseDate

        // If the parsed time is between midnight and 4 AM, and it's earlier than baseDate,
        // disambiguate whether it's same day (before batch) or next day (after midnight crossing)
        if startHour < 4 && startDate < baseDate {
            let nextDayStartDate = calendar.date(byAdding: .day, value: 1, to: startDate) ?? startDate

            // Pick whichever is closer to batch start time
            let sameDayDistance = abs(startDate.timeIntervalSince(baseDate))
            let nextDayDistance = abs(nextDayStartDate.timeIntervalSince(baseDate))

            if nextDayDistance < sameDayDistance {
                // Next day is closer - legitimate midnight crossing
                startDate = nextDayStartDate
            }
            // Otherwise keep same day (LLM provided time before batch started)
        }

        let startTs = Int(startDate.timeIntervalSince1970)

        let endComponents = calendar.dateComponents([.hour, .minute], from: endTime)
        guard let endHour = endComponents.hour, let endMinute = endComponents.minute else { return nil }

        var endDate = calendar.date(bySettingHour: endHour, minute: endMinute, second: 0, of: baseDate) ?? baseDate

        // Disambiguate end time day using same logic as start time
        if endHour < 4 && endDate < baseDate {
            let nextDayEndDate = calendar.date(byAdding: .day, value: 1, to: endDate) ?? endDate

            let sameDayDistance = abs(endDate.timeIntervalSince(baseDate))
            let nextDayDistance = abs(nextDayEndDate.timeIntervalSince(baseDate))

            if nextDayDistance < sameDayDistance {
                endDate = nextDayEndDate
            }
        }

        // Handle midnight crossing: if end time is before start time, it must be the next day
        if endDate < startDate {
            endDate = calendar.date(byAdding: .day, value: 1, to: endDate) ?? endDate
        }

        let endTs = Int(endDate.timeIntervalSince1970)

        try? timedWrite("saveTimelineCardShell") {
            db in
            // Encode metadata as an object for forward-compatibility
            let meta = TimelineMetadata(
                distractions: card.distractions,
                appSites: card.appSites,
                isBackupGenerated: card.isBackupGenerated
            )
            let metadataString: String? = (try? encoder.encode(meta)).flatMap { String(data: $0, encoding: .utf8) }

            // Calculate the day string using 4 AM boundary rules
            let (dayString, _, _) = startDate.getDayInfoFor4AMBoundary()

            try db.execute(sql: """
                INSERT INTO timeline_cards(
                    batch_id, start, end, start_ts, end_ts, day, title,
                    summary, category, subcategory, detailed_summary, metadata
                    -- video_summary_url is omitted here
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, arguments: [
                batchId, card.startTimestamp, card.endTimestamp, startTs, endTs, dayString, card.title,
                card.summary, card.category, card.subcategory, card.detailedSummary, metadataString
            ])
            lastId = db.lastInsertedRowID
        }
        return lastId
    }

    func updateTimelineCardVideoURL(cardId: Int64, videoSummaryURL: String) {
        try? timedWrite("updateTimelineCardVideoURL") {
            db in
            try db.execute(sql: """
                UPDATE timeline_cards
                SET video_summary_url = ?
                WHERE id = ?
            """, arguments: [videoSummaryURL, cardId])
        }
    }

    func updateTimelineCardCategory(cardId: Int64, category: String) {
        let trimmed = category.trimmingCharacters(in: .whitespacesAndNewlines)
        guard trimmed.isEmpty == false else { return }

        try? timedWrite("updateTimelineCardCategory") { db in
            try db.execute(sql: """
                UPDATE timeline_cards
                SET category = ?
                WHERE id = ?
            """, arguments: [trimmed, cardId])
        }
    }

    func fetchReviewRatingSegments(overlapping startTs: Int, endTs: Int) -> [TimelineReviewRatingSegment] {
        guard endTs > startTs else { return [] }

        return (try? timedRead("fetchReviewRatingSegments") { db in
            try Row.fetchAll(db, sql: """
                SELECT id, start_ts, end_ts, rating
                FROM timeline_review_ratings
                WHERE NOT (end_ts <= ? OR start_ts >= ?)
                ORDER BY start_ts ASC
            """, arguments: [startTs, endTs]).map { row in
                TimelineReviewRatingSegment(
                    id: row["id"],
                    startTs: row["start_ts"],
                    endTs: row["end_ts"],
                    rating: row["rating"]
                )
            }
        }) ?? []
    }

    func applyReviewRating(startTs: Int, endTs: Int, rating: String) {
        guard endTs > startTs else { return }

        try? timedWrite("applyReviewRating") { db in
            let overlappingRows = try Row.fetchAll(db, sql: """
                SELECT id, start_ts, end_ts, rating
                FROM timeline_review_ratings
                WHERE NOT (end_ts <= ? OR start_ts >= ?)
                ORDER BY start_ts ASC
            """, arguments: [startTs, endTs])

            var deleteIds: [Int64] = []
            var fragments: [(start: Int, end: Int, rating: String)] = []

            for row in overlappingRows {
                let id: Int64 = row["id"]
                let existingStart: Int = row["start_ts"]
                let existingEnd: Int = row["end_ts"]
                let existingRating: String = row["rating"]

                deleteIds.append(id)

                if existingStart < startTs {
                    let fragmentEnd = min(startTs, existingEnd)
                    if fragmentEnd > existingStart {
                        fragments.append((start: existingStart, end: fragmentEnd, rating: existingRating))
                    }
                }

                if existingEnd > endTs {
                    let fragmentStart = max(endTs, existingStart)
                    if existingEnd > fragmentStart {
                        fragments.append((start: fragmentStart, end: existingEnd, rating: existingRating))
                    }
                }
            }

            if deleteIds.isEmpty == false {
                let placeholders = Array(repeating: "?", count: deleteIds.count).joined(separator: ",")
                try db.execute(sql: """
                    DELETE FROM timeline_review_ratings
                    WHERE id IN (\(placeholders))
                """, arguments: StatementArguments(deleteIds))
            }

            for fragment in fragments {
                try db.execute(sql: """
                    INSERT INTO timeline_review_ratings (start_ts, end_ts, rating)
                    VALUES (?, ?, ?)
                """, arguments: [fragment.start, fragment.end, fragment.rating])
            }

            try db.execute(sql: """
                INSERT INTO timeline_review_ratings (start_ts, end_ts, rating)
                VALUES (?, ?, ?)
            """, arguments: [startTs, endTs, rating])
        }
    }

    func fetchUnreviewedTimelineCardCount(forDay day: String, coverageThreshold: Double = 0.8) -> Int {
        guard let dayDate = dateFormatter.date(from: day) else { return 0 }
        let calendar = Calendar.current
        guard let dayStart = calendar.date(bySettingHour: 4, minute: 0, second: 0, of: dayDate) else { return 0 }
        let dayEnd = calendar.date(byAdding: .day, value: 1, to: dayStart) ?? dayStart
        let dayStartTs = Int(dayStart.timeIntervalSince1970)
        let dayEndTs = Int(dayEnd.timeIntervalSince1970)

        let cardFetch = (try? timedRead("fetchUnreviewedTimelineCardCount.cards") { db -> (cards: [(start: Int, end: Int)], invalidCount: Int) in
            var invalidCount = 0
            let rows = try Row.fetchAll(db, sql: """
                SELECT start_ts, end_ts, category
                FROM timeline_cards
                WHERE start_ts >= ? AND start_ts < ?
                  AND is_deleted = 0
            """, arguments: [dayStartTs, dayEndTs])
            let cards = rows.compactMap { row -> (start: Int, end: Int)? in
                let category: String = row["category"]
                if category.trimmingCharacters(in: .whitespacesAndNewlines)
                    .caseInsensitiveCompare("System") == .orderedSame {
                    return nil
                }
                guard let start: Int = row["start_ts"], let end: Int = row["end_ts"], end > start else {
                    invalidCount += 1
                    return nil
                }
                return (start: start, end: end)
            }
            return (cards, invalidCount)
        })

        let cards = cardFetch?.cards ?? []
        var unreviewedCount = cardFetch?.invalidCount ?? 0

        if cards.isEmpty {
            return unreviewedCount
        }

        let ratingSegments = fetchReviewRatingSegments(overlapping: dayStartTs, endTs: dayEndTs)
        let mergedSegments = mergeCoverageSegments(
            segments: ratingSegments,
            dayStartTs: dayStartTs,
            dayEndTs: dayEndTs
        )

        let sortedCards = cards.sorted { $0.start < $1.start }
        var segmentIndex = 0

        for card in sortedCards {
            let duration = card.end - card.start
            if duration <= 0 { continue }

            let covered = overlapSeconds(
                start: card.start,
                end: card.end,
                segments: mergedSegments,
                segmentIndex: &segmentIndex
            )
            let coverageRatio = Double(covered) / Double(duration)
            if coverageRatio < coverageThreshold {
                unreviewedCount += 1
            }
        }

        return unreviewedCount
    }

    private func mergeCoverageSegments(
        segments: [TimelineReviewRatingSegment],
        dayStartTs: Int,
        dayEndTs: Int
    ) -> [(start: Int, end: Int)] {
        var clipped: [(start: Int, end: Int)] = []
        clipped.reserveCapacity(segments.count)

        for segment in segments {
            let start = max(segment.startTs, dayStartTs)
            let end = min(segment.endTs, dayEndTs)
            if end > start {
                clipped.append((start: start, end: end))
            }
        }

        guard clipped.isEmpty == false else { return [] }
        clipped.sort { $0.start < $1.start }

        var merged: [(start: Int, end: Int)] = [clipped[0]]
        for segment in clipped.dropFirst() {
            var last = merged[merged.count - 1]
            if segment.start <= last.end {
                last.end = max(last.end, segment.end)
                merged[merged.count - 1] = last
            } else {
                merged.append(segment)
            }
        }
        return merged
    }

    private func overlapSeconds(
        start: Int,
        end: Int,
        segments: [(start: Int, end: Int)],
        segmentIndex: inout Int
    ) -> Int {
        guard end > start else { return 0 }

        while segmentIndex < segments.count, segments[segmentIndex].end <= start {
            segmentIndex += 1
        }

        var covered = 0
        var index = segmentIndex

        while index < segments.count, segments[index].start < end {
            let overlapStart = max(start, segments[index].start)
            let overlapEnd = min(end, segments[index].end)
            if overlapEnd > overlapStart {
                covered += overlapEnd - overlapStart
            }
            if segments[index].end <= end {
                index += 1
            } else {
                break
            }
        }

        return covered
    }

    // MARK: - Onboarding Card

    /// Creates a dummy "Installed Dayflow!" card when onboarding completes.
    /// This gives users an immediate example of what cards look like.
    func createOnboardingCard() {
        let now = Date()
        let startTime = now.addingTimeInterval(-13 * 60)  // 13 minute card

        // Format times as "h:mm a" (e.g., "2:30 PM")
        let timeFormatter = DateFormatter()
        timeFormatter.dateFormat = "h:mm a"
        timeFormatter.locale = Locale(identifier: "en_US_POSIX")

        let startTimeString = timeFormatter.string(from: startTime)
        let endTimeString = timeFormatter.string(from: now)

        let startTs = Int(startTime.timeIntervalSince1970)
        let endTs = Int(now.timeIntervalSince1970)

        // Calculate day using 4AM boundary
        let (dayString, _, _) = startTime.getDayInfoFor4AMBoundary()

        // Get the first non-idle category, fallback to "Work"
        let categories = CategoryPersistence.loadPersistedCategories()
        let category = categories.first(where: { !$0.isIdle })?.name ?? "Work"

        // Build summary based on selected LLM provider
        let summary = buildOnboardingSummary()

        // Build metadata with appSites
        let encoder = JSONEncoder()
        let meta = TimelineMetadata(
            distractions: nil,
            appSites: AppSites(primary: "dayflow.so", secondary: nil),
            isBackupGenerated: nil
        )
        let metadataString: String? = (try? encoder.encode(meta)).flatMap { String(data: $0, encoding: .utf8) }

        try? timedWrite("createOnboardingCard") { db in
            try db.execute(sql: """
                INSERT INTO timeline_cards(
                    batch_id, start, end, start_ts, end_ts, day, title,
                    summary, category, subcategory, detailed_summary, metadata
                )
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, arguments: [
                nil,  // batch_id is NULL for onboarding card
                startTimeString,
                endTimeString,
                startTs,
                endTs,
                dayString,
                "Installed Dayflow!",
                summary,
                category,
                "Setup",
                "",  // detailed_summary - empty string (not NULL, as GRDB decode expects non-optional)
                metadataString
            ])
        }
    }

    private func buildOnboardingSummary() -> String {
        let selectedProvider = UserDefaults.standard.string(forKey: "selectedLLMProvider") ?? "gemini"

        switch selectedProvider {
        case "gemini":
            return "You successfully installed Dayflow and configured it with Gemini AI. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"

        case "chatgpt_claude":
            // Check which CLI tool they picked
            let cliTool = UserDefaults.standard.string(forKey: "chatCLIPreferredTool") ?? "claude"
            if cliTool == "codex" {
                return "You successfully installed Dayflow with ChatGPT. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"
            } else {
                return "You successfully installed Dayflow with Claude. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"
            }

        case "ollama":
            // Check which local engine they picked
            let localEngine = UserDefaults.standard.string(forKey: "llmLocalEngine") ?? "ollama"
            if localEngine == "lmstudio" {
                return "You successfully installed Dayflow with LM Studio ‚Äî your data stays 100% on your device. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"
            } else {
                return "You successfully installed Dayflow with Ollama ‚Äî your data stays 100% on your device. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"
            }

        default:
            return "You successfully installed Dayflow. Come back in 30 minutes to see your first real activity card! ‚ú® (This is a sample card, so you can see what your timeline will look like.)"
        }
    }

    func fetchTimelineCards(forBatch batchId: Int64) -> [TimelineCard] {
        let decoder = JSONDecoder()
        return (try? timedRead("fetchTimelineCards(forBatch)") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM timeline_cards
                WHERE batch_id = ?
                  AND is_deleted = 0
                ORDER BY start ASC
            """, arguments: [batchId]).map { row in
                var distractions: [Distraction]? = nil
                var appSites: AppSites? = nil
                var isBackupGenerated: Bool? = nil
                if let metadataString: String = row["metadata"],
                   let jsonData = metadataString.data(using: .utf8) {
                    if let meta = try? decoder.decode(TimelineMetadata.self, from: jsonData) {
                        distractions = meta.distractions
                        appSites = meta.appSites
                        isBackupGenerated = meta.isBackupGenerated
                    } else if let legacy = try? decoder.decode([Distraction].self, from: jsonData) {
                        distractions = legacy
                    }
                }
                return TimelineCard(
                    recordId: row["id"],
                    batchId: batchId,
                    startTimestamp: row["start"] ?? "",
                    endTimestamp: row["end"] ?? "",
                    category: row["category"],
                    subcategory: row["subcategory"],
                    title: row["title"],
                    summary: row["summary"],
                    detailedSummary: row["detailed_summary"],
                    day: row["day"],
                    distractions: distractions,
                    videoSummaryURL: row["video_summary_url"],
                    otherVideoSummaryURLs: nil,
                    appSites: appSites,
                    isBackupGenerated: isBackupGenerated
                )
            }
        }) ?? []
    }

    // All batches, newest first
       func allBatches() -> [(id: Int64, start: Int, end: Int, status: String)] {
            (try? db.read { db in
                try Row.fetchAll(db, sql:
                    "SELECT id, batch_start_ts, batch_end_ts, status FROM analysis_batches ORDER BY id DESC"
                ).map { row in
                    (row["id"], row["batch_start_ts"], row["batch_end_ts"], row["status"])
                }
            }) ?? []
        }

    func fetchRecentAnalysisBatchesForDebug(limit: Int) -> [AnalysisBatchDebugEntry] {
        guard limit > 0 else { return [] }

        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT id, status, batch_start_ts, batch_end_ts, created_at, reason
                FROM analysis_batches
                ORDER BY id DESC
                LIMIT ?
            """, arguments: [limit]).map { row in
                AnalysisBatchDebugEntry(
                    id: row["id"],
                    status: row["status"] ?? "unknown",
                    startTs: row["batch_start_ts"] ?? 0,
                    endTs: row["batch_end_ts"] ?? 0,
                    createdAt: row["created_at"],
                    reason: row["reason"]
                )
            }
        }) ?? []
    }


    func fetchTimelineCards(forDay day: String) -> [TimelineCard] {
        let decoder = JSONDecoder()
        
        guard let dayDate = dateFormatter.date(from: day) else {
            return []
        }
        
        let calendar = Calendar.current
        
        // Get 4 AM of the given day as the start
        var startComponents = calendar.dateComponents([.year, .month, .day], from: dayDate)
        startComponents.hour = 4
        startComponents.minute = 0
        startComponents.second = 0
        guard let dayStart = calendar.date(from: startComponents) else { return [] }
        
        // Get 4 AM of the next day as the end
        guard let nextDay = calendar.date(byAdding: .day, value: 1, to: dayDate) else { return [] }
        var endComponents = calendar.dateComponents([.year, .month, .day], from: nextDay)
        endComponents.hour = 4
        endComponents.minute = 0
        endComponents.second = 0
        guard let dayEnd = calendar.date(from: endComponents) else { return [] }
        
        let startTs = Int(dayStart.timeIntervalSince1970)
        let endTs = Int(dayEnd.timeIntervalSince1970)

        let cards: [TimelineCard]? = try? timedRead("fetchTimelineCards(forDay:\(day))") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM timeline_cards
                WHERE start_ts >= ? AND start_ts < ?
                  AND is_deleted = 0
                ORDER BY start_ts ASC, start ASC
            """, arguments: [startTs, endTs])
            .map { row in
                // Decode metadata JSON (supports object or legacy array)
                var distractions: [Distraction]? = nil
                var appSites: AppSites? = nil
                var isBackupGenerated: Bool? = nil
                if let metadataString: String = row["metadata"],
                   let jsonData = metadataString.data(using: .utf8) {
                    if let meta = try? decoder.decode(TimelineMetadata.self, from: jsonData) {
                        distractions = meta.distractions
                        appSites = meta.appSites
                        isBackupGenerated = meta.isBackupGenerated
                    } else if let legacy = try? decoder.decode([Distraction].self, from: jsonData) {
                        distractions = legacy
                    }
                }

                // Create TimelineCard instance using renamed columns
                return TimelineCard(
                    recordId: row["id"],
                    batchId: row["batch_id"],
                    startTimestamp: row["start"] ?? "", // Use row["start"]
                    endTimestamp: row["end"] ?? "",   // Use row["end"]
                    category: row["category"],
                    subcategory: row["subcategory"],
                    title: row["title"],
                    summary: row["summary"],
                    detailedSummary: row["detailed_summary"],
                    day: row["day"],
                    distractions: distractions,
                    videoSummaryURL: row["video_summary_url"],
                    otherVideoSummaryURLs: nil,
                    appSites: appSites,
                    isBackupGenerated: isBackupGenerated
                )
            }
        }
        return cards ?? []
    }

    func fetchTimelineCardsByTimeRange(from: Date, to: Date) -> [TimelineCard] {
        let decoder = JSONDecoder()
        let fromTs = Int(from.timeIntervalSince1970)
        let toTs = Int(to.timeIntervalSince1970)


        let cards: [TimelineCard]? = try? timedRead("fetchTimelineCardsByTimeRange") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM timeline_cards
                WHERE ((start_ts < ? AND end_ts > ?)
                   OR (start_ts >= ? AND start_ts < ?))
                  AND is_deleted = 0
                  AND category != 'System'
                ORDER BY start_ts ASC
            """, arguments: [toTs, fromTs, fromTs, toTs])
            .map { row in
                // Decode metadata JSON (supports object or legacy array)
                var distractions: [Distraction]? = nil
                var appSites: AppSites? = nil
                var isBackupGenerated: Bool? = nil
                if let metadataString: String = row["metadata"],
                   let jsonData = metadataString.data(using: .utf8) {
                    if let meta = try? decoder.decode(TimelineMetadata.self, from: jsonData) {
                        distractions = meta.distractions
                        appSites = meta.appSites
                        isBackupGenerated = meta.isBackupGenerated
                    } else if let legacy = try? decoder.decode([Distraction].self, from: jsonData) {
                        distractions = legacy
                    }
                }

                // Create TimelineCard instance using renamed columns
                return TimelineCard(
                    recordId: row["id"],
                    batchId: row["batch_id"],
                    startTimestamp: row["start"] ?? "",
                    endTimestamp: row["end"] ?? "",
                    category: row["category"],
                    subcategory: row["subcategory"],
                    title: row["title"],
                    summary: row["summary"],
                    detailedSummary: row["detailed_summary"],
                    day: row["day"],
                    distractions: distractions,
                    videoSummaryURL: row["video_summary_url"],
                    otherVideoSummaryURLs: nil,
                    appSites: appSites,
                    isBackupGenerated: isBackupGenerated
                )
            }
        }
        let result = cards ?? []
        return result
    }

    /// Returns total minutes of tracked activities for the week containing the given date.
    /// Week starts on Monday at 4 AM and ends the following Monday at 4 AM.
    func fetchTotalMinutesTrackedForWeek(containing date: Date) -> Double {
        let calendar = Calendar.current

        // Find the Monday of the week containing this date
        var weekStart = calendar.date(from: calendar.dateComponents([.yearForWeekOfYear, .weekOfYear], from: date))!
        // Set to 4 AM on that Monday
        weekStart = calendar.date(bySettingHour: 4, minute: 0, second: 0, of: weekStart) ?? weekStart

        // If current date is before 4 AM Monday, go back one week
        if date < weekStart {
            weekStart = calendar.date(byAdding: .weekOfYear, value: -1, to: weekStart) ?? weekStart
        }

        // Week ends at 4 AM the following Monday
        let weekEnd = calendar.date(byAdding: .weekOfYear, value: 1, to: weekStart) ?? weekStart

        let startTs = Int(weekStart.timeIntervalSince1970)
        let endTs = Int(weekEnd.timeIntervalSince1970)

        // Query sum of (end_ts - start_ts) for all non-deleted cards in the week
        let totalSeconds: Double? = try? timedRead("fetchTotalMinutesTrackedForWeek") { db in
            try Double.fetchOne(db, sql: """
                SELECT COALESCE(SUM(end_ts - start_ts), 0)
                FROM timeline_cards
                WHERE start_ts >= ? AND start_ts < ?
                AND is_deleted = 0
                AND category != 'System'
            """, arguments: [startTs, endTs])
        }

        return (totalSeconds ?? 0) / 60.0
    }

    func fetchRecentTimelineCardsForDebug(limit: Int) -> [TimelineCardDebugEntry] {
        guard limit > 0 else { return [] }

        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT batch_id, day, start, end, category, subcategory, title, summary, detailed_summary, created_at
                FROM timeline_cards
                WHERE is_deleted = 0
                ORDER BY created_at DESC, id DESC
                LIMIT ?
            """, arguments: [limit]).map { row in
                TimelineCardDebugEntry(
                    createdAt: row["created_at"],
                    batchId: row["batch_id"],
                    day: row["day"] ?? "",
                    startTime: row["start"] ?? "",
                    endTime: row["end"] ?? "",
                    category: row["category"],
                    subcategory: row["subcategory"],
                    title: row["title"],
                    summary: row["summary"],
                    detailedSummary: row["detailed_summary"]
                )
            }
        }) ?? []
    }

    func fetchRecentLLMCallsForDebug(limit: Int) -> [LLMCallDebugEntry] {
        guard limit > 0 else { return [] }

        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT created_at, batch_id, call_group_id, attempt, provider, model, operation, status, latency_ms, http_status, request_method, request_url, request_body, response_body, error_message
                FROM llm_calls
                ORDER BY created_at DESC, id DESC
                LIMIT ?
            """, arguments: [limit]).map { row in
                LLMCallDebugEntry(
                    createdAt: row["created_at"],
                    batchId: row["batch_id"],
                    callGroupId: row["call_group_id"],
                    attempt: row["attempt"] ?? 0,
                    provider: row["provider"] ?? "",
                    model: row["model"],
                    operation: row["operation"] ?? "",
                    status: row["status"] ?? "",
                    latencyMs: row["latency_ms"],
                    httpStatus: row["http_status"],
                    requestMethod: row["request_method"],
                    requestURL: row["request_url"],
                    requestBody: row["request_body"],
                    responseBody: row["response_body"],
                    errorMessage: row["error_message"]
                )
            }
        }) ?? []
    }

    func updateStorageLimit(bytes: Int64) {
        let previous = StoragePreferences.recordingsLimitBytes
        StoragePreferences.recordingsLimitBytes = bytes

        if bytes < previous {
            purgeIfNeeded()
        }
    }

    func fetchLLMCallsForBatches(batchIds: [Int64], limit: Int) -> [LLMCallDebugEntry] {
        guard !batchIds.isEmpty, limit > 0 else { return [] }

        // Create SQL placeholders for batch IDs
        let placeholders = Array(repeating: "?", count: batchIds.count).joined(separator: ",")

        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT created_at, batch_id, call_group_id, attempt, provider, model, operation, status, latency_ms, http_status, request_method, request_url, request_body, response_body, error_message
                FROM llm_calls
                WHERE batch_id IN (\(placeholders))
                ORDER BY created_at DESC, id DESC
                LIMIT ?
            """, arguments: StatementArguments(batchIds + [Int64(limit)])).map { row in
                LLMCallDebugEntry(
                    createdAt: row["created_at"],
                    batchId: row["batch_id"],
                    callGroupId: row["call_group_id"],
                    attempt: row["attempt"] ?? 0,
                    provider: row["provider"] ?? "",
                    model: row["model"],
                    operation: row["operation"] ?? "",
                    status: row["status"] ?? "",
                    latencyMs: row["latency_ms"],
                    httpStatus: row["http_status"],
                    requestMethod: row["request_method"],
                    requestURL: row["request_url"],
                    requestBody: row["request_body"],
                    responseBody: row["response_body"],
                    errorMessage: row["error_message"]
                )
            }
        }) ?? []
    }

    /// Fetch a specific timeline card by ID including timestamp fields
    func fetchTimelineCard(byId id: Int64) -> TimelineCardWithTimestamps? {
        let decoder = JSONDecoder()

        return try? timedRead("fetchTimelineCard(byId)") { db in
            guard let row = try Row.fetchOne(db, sql: """
                SELECT * FROM timeline_cards
                WHERE id = ?
                  AND is_deleted = 0
            """, arguments: [id]) else { return nil }
            
            // Decode distractions from metadata JSON
            var distractions: [Distraction]? = nil
            if let metadataString: String = row["metadata"],
               let jsonData = metadataString.data(using: .utf8) {
                if let meta = try? decoder.decode(TimelineMetadata.self, from: jsonData) {
                    distractions = meta.distractions
                } else if let legacy = try? decoder.decode([Distraction].self, from: jsonData) {
                    distractions = legacy
                }
            }
            
            return TimelineCardWithTimestamps(
                id: id,
                startTimestamp: row["start"] ?? "",
                endTimestamp: row["end"] ?? "",
                startTs: row["start_ts"] ?? 0,
                endTs: row["end_ts"] ?? 0,
                category: row["category"],
                subcategory: row["subcategory"],
                title: row["title"],
                summary: row["summary"],
                detailedSummary: row["detailed_summary"],
                day: row["day"],
                distractions: distractions,
                videoSummaryURL: row["video_summary_url"]
            )
        }
    }
    
    func replaceTimelineCardsInRange(from: Date, to: Date, with newCards: [TimelineCardShell], batchId: Int64) -> (insertedIds: [Int64], deletedVideoPaths: [String]) {
        let fromTs = Int(from.timeIntervalSince1970)
        let toTs = Int(to.timeIntervalSince1970)
        
        
        let encoder = JSONEncoder()
        var insertedIds: [Int64] = []
        var videoPaths: [String] = []
        
        // Setup date formatter for parsing clock times
        let timeFormatter = DateFormatter()
        timeFormatter.dateFormat = "h:mm a"
        timeFormatter.locale = Locale(identifier: "en_US_POSIX")

        try? timedWrite("replaceTimelineCardsInRange(\(newCards.count)_cards)") { db in
            // First, fetch the video paths that will be soft-deleted
            // Note: We exclude error cards (category='System') from other batches to preserve them
            let videoRows = try Row.fetchAll(db, sql: """
                SELECT video_summary_url FROM timeline_cards
                WHERE ((start_ts < ? AND end_ts > ?)
                   OR (start_ts >= ? AND start_ts < ?))
                   AND video_summary_url IS NOT NULL
                   AND is_deleted = 0
                   AND (category != 'System' OR batch_id = ?)
            """, arguments: [toTs, fromTs, fromTs, toTs, batchId])

            videoPaths = videoRows.compactMap { $0["video_summary_url"] as? String }

            // Fetch the cards that will be deleted for debugging
            let cardsToDelete = try Row.fetchAll(db, sql: """
                SELECT id, start, end, title FROM timeline_cards
                WHERE ((start_ts < ? AND end_ts > ?)
                   OR (start_ts >= ? AND start_ts < ?))
                   AND is_deleted = 0
                   AND (category != 'System' OR batch_id = ?)
            """, arguments: [toTs, fromTs, fromTs, toTs, batchId])

            for _ in cardsToDelete {
                // Cards being deleted - no-op needed, just iterating to trigger side effects
            }

            // Soft delete existing cards in the range using timestamp columns
            // Preserve error cards (category='System') from other batches so they remain visible
            try db.execute(sql: """
                UPDATE timeline_cards
                SET is_deleted = 1
                WHERE ((start_ts < ? AND end_ts > ?)
                   OR (start_ts >= ? AND start_ts < ?))
                   AND is_deleted = 0
                   AND (category != 'System' OR batch_id = ?)
            """, arguments: [toTs, fromTs, fromTs, toTs, batchId])

            // Verify soft deletion (count remaining active cards)
            let remainingCount = try Int.fetchOne(db, sql: """
                SELECT COUNT(*) FROM timeline_cards
                WHERE ((start_ts < ? AND end_ts > ?)
                   OR (start_ts >= ? AND start_ts < ?))
                   AND is_deleted = 0
            """, arguments: [toTs, fromTs, fromTs, toTs]) ?? 0
            
            if remainingCount > 0 {
            } else {
            }
            
            // Insert new cards
            for card in newCards {
                // Encode metadata object with distractions and appSites
                let meta = TimelineMetadata(
                    distractions: card.distractions,
                    appSites: card.appSites,
                    isBackupGenerated: card.isBackupGenerated
                )
                let metadataString: String? = (try? encoder.encode(meta)).flatMap { String(data: $0, encoding: .utf8) }

                // Resolve clock-only timestamps by picking the nearest day to the window midpoint
                let calendar = Calendar.current
                let anchor = from.addingTimeInterval(to.timeIntervalSince(from) / 2.0)

                let resolveClock: (Int, Int) -> Date = { hour, minute in
                    guard let sameDay = calendar.date(bySettingHour: hour, minute: minute, second: 0, of: anchor) else {
                        return anchor
                    }
                    let previousDay = calendar.date(byAdding: .day, value: -1, to: sameDay) ?? sameDay
                    let nextDay = calendar.date(byAdding: .day, value: 1, to: sameDay) ?? sameDay

                    let candidates = [previousDay, sameDay, nextDay]
                    return candidates.min { lhs, rhs in
                        abs(lhs.timeIntervalSince(anchor)) < abs(rhs.timeIntervalSince(anchor))
                    } ?? sameDay
                }

                guard let startTime = timeFormatter.date(from: card.startTimestamp),
                      let endTime = timeFormatter.date(from: card.endTimestamp) else {
                    continue
                }

                let startComponents = calendar.dateComponents([.hour, .minute], from: startTime)
                guard let startHour = startComponents.hour, let startMinute = startComponents.minute else { continue }

                let startDate = resolveClock(startHour, startMinute)

                let startTs = Int(startDate.timeIntervalSince1970)

                let endComponents = calendar.dateComponents([.hour, .minute], from: endTime)
                guard let endHour = endComponents.hour, let endMinute = endComponents.minute else { continue }

                var endDate = resolveClock(endHour, endMinute)

                // Handle midnight crossing: if end time is before start time, it must be the next day
                if endDate < startDate {
                    endDate = calendar.date(byAdding: .day, value: 1, to: endDate) ?? endDate
                }

                let endTs = Int(endDate.timeIntervalSince1970)

                // Calculate the day string using 4 AM boundary rules
                let (dayString, _, _) = startDate.getDayInfoFor4AMBoundary()

                try db.execute(sql: """
                    INSERT INTO timeline_cards(
                        batch_id, start, end, start_ts, end_ts, day, title,
                        summary, category, subcategory, detailed_summary, metadata
                    )
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, arguments: [
                    batchId, card.startTimestamp, card.endTimestamp, startTs, endTs, dayString, card.title,
                    card.summary, card.category, card.subcategory, card.detailedSummary, metadataString
                ])
                
                // Capture the ID of the inserted card
                let insertedId = db.lastInsertedRowID
                insertedIds.append(insertedId)
            }
        }
        
        return (insertedIds, videoPaths)
    }

    // Note: Transcript storage methods removed in favor of Observations table
    
    
    func saveObservations(batchId: Int64, observations: [Observation]) {
        guard !observations.isEmpty else { return }
        try? timedWrite("saveObservations(\(observations.count)_items)") { db in
            for obs in observations {
                try db.execute(sql: """
                    INSERT INTO observations(
                        batch_id, start_ts, end_ts, observation, metadata, llm_model
                    )
                    VALUES (?, ?, ?, ?, ?, ?)
                """, arguments: [
                    batchId, obs.startTs, obs.endTs, obs.observation, 
                    obs.metadata, obs.llmModel
                ])
            }
        }
    }
    
    func fetchObservations(batchId: Int64) -> [Observation] {
        (try? timedRead("fetchObservations(batchId)") { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM observations 
                WHERE batch_id = ? 
                ORDER BY start_ts ASC
            """, arguments: [batchId]).map { row in
                Observation(
                    id: row["id"],
                    batchId: row["batch_id"],
                    startTs: row["start_ts"],
                    endTs: row["end_ts"],
                    observation: row["observation"],
                    metadata: row["metadata"],
                    llmModel: row["llm_model"],
                    createdAt: row["created_at"]
                )
            }
        }) ?? []
    }
    
    func fetchObservationsByTimeRange(from: Date, to: Date) -> [Observation] {
        let fromTs = Int(from.timeIntervalSince1970)
        let toTs = Int(to.timeIntervalSince1970)
        
        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM observations 
                WHERE (start_ts < ? AND end_ts > ?) 
                   OR (start_ts >= ? AND start_ts < ?)
                ORDER BY start_ts ASC
            """, arguments: [toTs, fromTs, fromTs, toTs]).map { row in
                Observation(
                    id: row["id"],
                    batchId: row["batch_id"],
                    startTs: row["start_ts"],
                    endTs: row["end_ts"],
                    observation: row["observation"],
                    metadata: row["metadata"],
                    llmModel: row["llm_model"],
                    createdAt: row["created_at"]
                )
            }
        }) ?? []
    }
    
    
    func updateBatch(_ batchId: Int64, status: String, reason: String? = nil) {
        try? db.write { db in
            let sql = """
                UPDATE analysis_batches
                SET status = ?, reason = ?
                WHERE id = ?
            """
            try db.execute(sql: sql, arguments: [status, reason, batchId])
        }
    }
    
    var dateFormatter: DateFormatter {
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd"
        return formatter
    }

    func insertLLMCall(_ rec: LLMCallDBRecord) {
        try? db.write { db in
            try db.execute(sql: """
                INSERT INTO llm_calls (
                    batch_id, call_group_id, attempt, provider, model, operation,
                    status, latency_ms, http_status, request_method, request_url,
                    request_headers, request_body, response_headers, response_body,
                    error_domain, error_code, error_message
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """,
            arguments: [
                rec.batchId,
                rec.callGroupId,
                rec.attempt,
                rec.provider,
                rec.model,
                rec.operation,
                rec.status,
                rec.latencyMs,
                rec.httpStatus,
                rec.requestMethod,
                rec.requestURL,
                rec.requestHeadersJSON,
                rec.requestBody,
                rec.responseHeadersJSON,
                rec.responseBody,
                rec.errorDomain,
                rec.errorCode,
                rec.errorMessage
            ])
        }
    }
    
    func fetchObservations(startTs: Int, endTs: Int) -> [Observation] {
        (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT * FROM observations 
                WHERE start_ts >= ? AND end_ts <= ?
                ORDER BY start_ts ASC
            """, arguments: [startTs, endTs]).map { row in
                Observation(
                    id: row["id"],
                    batchId: row["batch_id"],
                    startTs: row["start_ts"],
                    endTs: row["end_ts"],
                    observation: row["observation"],
                    metadata: row["metadata"],
                    llmModel: row["llm_model"],
                    createdAt: row["created_at"]
                )
            }
        }) ?? []
    }

    func getTimestampsForVideoFiles(paths: [String]) -> [String: (startTs: Int, endTs: Int)] {
        guard !paths.isEmpty else { return [:] }
        var out: [String: (Int, Int)] = [:]
        let placeholders = Array(repeating: "?", count: paths.count).joined(separator: ",")
        let sql = "SELECT file_url, start_ts, end_ts FROM chunks WHERE file_url IN (\(placeholders)) AND (is_deleted = 0 OR is_deleted IS NULL)"
        try? db.read { db in
            let rows = try Row.fetchAll(db, sql: sql, arguments: StatementArguments(paths))
            for row in rows {
                if let path: String = row["file_url"],
                   let start: Int  = row["start_ts"],
                   let end:   Int  = row["end_ts"] {
                    out[path] = (start, end)
                }
            }
        }
        return out
    }

    
    func deleteTimelineCards(forDay day: String) -> [String] {
        var videoPaths: [String] = []
        
        guard let dayDate = dateFormatter.date(from: day) else {
            return []
        }
        
        let calendar = Calendar.current
        
        // Get 4 AM of the given day as the start
        var startComponents = calendar.dateComponents([.year, .month, .day], from: dayDate)
        startComponents.hour = 4
        startComponents.minute = 0
        startComponents.second = 0
        guard let dayStart = calendar.date(from: startComponents) else { return [] }
        
        // Get 4 AM of the next day as the end
        guard let nextDay = calendar.date(byAdding: .day, value: 1, to: dayDate) else { return [] }
        var endComponents = calendar.dateComponents([.year, .month, .day], from: nextDay)
        endComponents.hour = 4
        endComponents.minute = 0
        endComponents.second = 0
        guard let dayEnd = calendar.date(from: endComponents) else { return [] }
        
        let startTs = Int(dayStart.timeIntervalSince1970)
        let endTs = Int(dayEnd.timeIntervalSince1970)

        try? timedWrite("deleteTimelineCards(forDay:\(day))") { db in
            // First fetch all video paths before soft deletion
            let rows = try Row.fetchAll(db, sql: """
                SELECT video_summary_url FROM timeline_cards
                WHERE start_ts >= ? AND start_ts < ?
                  AND video_summary_url IS NOT NULL
                  AND is_deleted = 0
            """, arguments: [startTs, endTs])

            videoPaths = rows.compactMap { $0["video_summary_url"] as? String }

            // Soft delete the timeline cards by setting is_deleted = 1
            try db.execute(sql: """
                UPDATE timeline_cards
                SET is_deleted = 1
                WHERE start_ts >= ? AND start_ts < ?
                  AND is_deleted = 0
            """, arguments: [startTs, endTs])
        }
        
        return videoPaths
    }

    func deleteTimelineCards(forBatchIds batchIds: [Int64]) -> [String] {
        guard !batchIds.isEmpty else { return [] }
        var videoPaths: [String] = []
        let placeholders = Array(repeating: "?", count: batchIds.count).joined(separator: ",")

        do {
            try timedWrite("deleteTimelineCards(forBatchIds:\(batchIds.count))") { db in
                // Fetch video paths for active records only
                let rows = try Row.fetchAll(
                    db,
                    sql: """
                        SELECT video_summary_url
                        FROM timeline_cards
                        WHERE batch_id IN (\(placeholders))
                          AND video_summary_url IS NOT NULL
                          AND is_deleted = 0
                    """,
                    arguments: StatementArguments(batchIds)
                )

                videoPaths = rows.compactMap { $0["video_summary_url"] as? String }

                // Soft delete the records
                try db.execute(
                    sql: """
                        UPDATE timeline_cards
                        SET is_deleted = 1
                        WHERE batch_id IN (\(placeholders))
                          AND is_deleted = 0
                    """,
                    arguments: StatementArguments(batchIds)
                )
            }
        } catch {
            print("deleteTimelineCards(forBatchIds:) failed: \(error)")
        }

        return videoPaths
    }

    func deleteObservations(forBatchIds batchIds: [Int64]) {
        guard !batchIds.isEmpty else { return }
        
        try? db.write { db in
            let placeholders = Array(repeating: "?", count: batchIds.count).joined(separator: ",")
            try db.execute(sql: """
                DELETE FROM observations WHERE batch_id IN (\(placeholders))
            """, arguments: StatementArguments(batchIds))
        }
    }
    
    func resetBatchStatuses(forDay day: String) -> [Int64] {
        var affectedBatchIds: [Int64] = []
        
        // Calculate day boundaries (4 AM to 4 AM)
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd"
        guard let dayDate = formatter.date(from: day) else { return [] }
        
        let calendar = Calendar.current
        guard let startOfDay = calendar.date(bySettingHour: 4, minute: 0, second: 0, of: dayDate) else { return [] }
        let endOfDay = calendar.date(byAdding: .day, value: 1, to: startOfDay)!
        
        let startTs = Int(startOfDay.timeIntervalSince1970)
        let endTs = Int(endOfDay.timeIntervalSince1970)
        
        try? db.write { db in
            // Fetch batch IDs first
            let rows = try Row.fetchAll(db, sql: """
                SELECT id FROM analysis_batches
                WHERE batch_start_ts >= ? AND batch_end_ts <= ?
                  AND status IN ('completed', 'failed', 'processing', 'analyzed')
            """, arguments: [startTs, endTs])
            
            affectedBatchIds = rows.compactMap { $0["id"] as? Int64 }
            
            // Reset their status to pending
            if !affectedBatchIds.isEmpty {
                let placeholders = Array(repeating: "?", count: affectedBatchIds.count).joined(separator: ",")
                try db.execute(sql: """
                    UPDATE analysis_batches
                    SET status = 'pending', reason = NULL, llm_metadata = NULL
                    WHERE id IN (\(placeholders))
                """, arguments: StatementArguments(affectedBatchIds))
            }
        }
        
        return affectedBatchIds
    }

    func resetBatchStatuses(forBatchIds batchIds: [Int64]) -> [Int64] {
        guard !batchIds.isEmpty else { return [] }
        var affectedBatchIds: [Int64] = []
        let placeholders = Array(repeating: "?", count: batchIds.count).joined(separator: ",")

        do {
            try timedWrite("resetBatchStatuses(forBatchIds:\(batchIds.count))") { db in
                let rows = try Row.fetchAll(
                    db,
                    sql: """
                        SELECT id FROM analysis_batches
                        WHERE id IN (\(placeholders))
                    """,
                    arguments: StatementArguments(batchIds)
                )

                affectedBatchIds = rows.compactMap { $0["id"] as? Int64 }
                guard !affectedBatchIds.isEmpty else { return }

                let affectedPlaceholders = Array(repeating: "?", count: affectedBatchIds.count).joined(separator: ",")
                try db.execute(
                    sql: """
                        UPDATE analysis_batches
                        SET status = 'pending', reason = NULL, llm_metadata = NULL
                        WHERE id IN (\(affectedPlaceholders))
                    """,
                    arguments: StatementArguments(affectedBatchIds)
                )
            }
        } catch {
            print("resetBatchStatuses(forBatchIds:) failed: \(error)")
        }

        return affectedBatchIds
    }
    
    func fetchBatches(forDay day: String) -> [(id: Int64, startTs: Int, endTs: Int, status: String)] {
        // Calculate day boundaries (4 AM to 4 AM)
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd"
        guard let dayDate = formatter.date(from: day) else { return [] }
        
        let calendar = Calendar.current
        guard let startOfDay = calendar.date(bySettingHour: 4, minute: 0, second: 0, of: dayDate) else { return [] }
        let endOfDay = calendar.date(byAdding: .day, value: 1, to: startOfDay)!
        
        let startTs = Int(startOfDay.timeIntervalSince1970)
        let endTs = Int(endOfDay.timeIntervalSince1970)
        
        return (try? db.read { db in
            try Row.fetchAll(db, sql: """
                SELECT id, batch_start_ts, batch_end_ts, status FROM analysis_batches
                WHERE batch_start_ts >= ? AND batch_end_ts <= ?
                ORDER BY batch_start_ts ASC
            """, arguments: [startTs, endTs]).map { row in
                (
                    id: row["id"] as? Int64 ?? 0,
                    startTs: Int(row["batch_start_ts"] as? Int64 ?? 0),
                    endTs: Int(row["batch_end_ts"] as? Int64 ?? 0),
                    status: row["status"] as? String ?? ""
                )
            }
        }) ?? []
    }
    
    // MARK: - Journal Entry Methods

    /// Fetch journal entry for a specific day (using 4AM boundary format)
    func fetchJournalEntry(forDay day: String) -> JournalEntry? {
        return try? timedRead("fetchJournalEntry(forDay:\(day))") { db in
            guard let row = try Row.fetchOne(db, sql: """
                SELECT * FROM journal_entries WHERE day = ?
            """, arguments: [day]) else { return nil }

            return JournalEntry(
                id: row["id"],
                day: row["day"],
                intentions: row["intentions"],
                notes: row["notes"],
                goals: row["goals"],
                reflections: row["reflections"],
                summary: row["summary"],
                status: row["status"] ?? "draft",
                createdAt: row["created_at"],
                updatedAt: row["updated_at"]
            )
        }
    }

    /// Save or update a journal entry (upsert)
    func saveJournalEntry(_ entry: JournalEntry) {
        try? timedWrite("saveJournalEntry") { db in
            try db.execute(sql: """
                INSERT INTO journal_entries (day, intentions, notes, goals, reflections, summary, status, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
                ON CONFLICT(day) DO UPDATE SET
                    intentions = excluded.intentions,
                    notes = excluded.notes,
                    goals = excluded.goals,
                    reflections = excluded.reflections,
                    summary = excluded.summary,
                    status = excluded.status,
                    updated_at = CURRENT_TIMESTAMP
            """, arguments: [
                entry.day,
                entry.intentions,
                entry.notes,
                entry.goals,
                entry.reflections,
                entry.summary,
                entry.status
            ])
        }
    }

    /// Update just the intentions/notes/goals fields (morning form)
    func updateJournalIntentions(day: String, intentions: String?, notes: String?, goals: String?) {
        try? timedWrite("updateJournalIntentions") { db in
            // Check if entry exists
            let exists = try Int.fetchOne(db, sql: "SELECT COUNT(*) FROM journal_entries WHERE day = ?", arguments: [day]) ?? 0

            if exists > 0 {
                try db.execute(sql: """
                    UPDATE journal_entries
                    SET intentions = ?, notes = ?, goals = ?, status = 'intentions_set', updated_at = CURRENT_TIMESTAMP
                    WHERE day = ?
                """, arguments: [intentions, notes, goals, day])
            } else {
                try db.execute(sql: """
                    INSERT INTO journal_entries (day, intentions, notes, goals, status)
                    VALUES (?, ?, ?, ?, 'intentions_set')
                """, arguments: [day, intentions, notes, goals])
            }
        }
    }

    /// Update just the reflections field (evening reflection)
    func updateJournalReflections(day: String, reflections: String?) {
        try? timedWrite("updateJournalReflections") { db in
            let exists = try Int.fetchOne(db, sql: "SELECT COUNT(*) FROM journal_entries WHERE day = ?", arguments: [day]) ?? 0

            if exists > 0 {
                try db.execute(sql: """
                    UPDATE journal_entries
                    SET reflections = ?, updated_at = CURRENT_TIMESTAMP
                    WHERE day = ?
                """, arguments: [reflections, day])
            } else {
                try db.execute(sql: """
                    INSERT INTO journal_entries (day, reflections, status)
                    VALUES (?, ?, 'draft')
                """, arguments: [day, reflections])
            }
        }
    }

    /// Update just the AI summary field
    func updateJournalSummary(day: String, summary: String?) {
        try? timedWrite("updateJournalSummary") { db in
            let exists = try Int.fetchOne(db, sql: "SELECT COUNT(*) FROM journal_entries WHERE day = ?", arguments: [day]) ?? 0

            if exists > 0 {
                try db.execute(sql: """
                    UPDATE journal_entries
                    SET summary = ?, status = 'complete', updated_at = CURRENT_TIMESTAMP
                    WHERE day = ?
                """, arguments: [summary, day])
            } else {
                try db.execute(sql: """
                    INSERT INTO journal_entries (day, summary, status)
                    VALUES (?, ?, 'complete')
                """, arguments: [day, summary])
            }
        }
    }

    /// Fetch the most recent journal summary within the last N days
    /// Returns the day string and summary text, or nil if none found
    func fetchRecentJournalSummary(withinDays days: Int) -> (day: String, summary: String)? {
        let calendar = Calendar.current
        let today = Date()
        guard let cutoffDate = calendar.date(byAdding: .day, value: -days, to: today) else { return nil }
        let cutoffDay = DateFormatter.yyyyMMdd.string(from: cutoffDate)

        return try? timedRead("fetchRecentJournalSummary") { db in
            guard let row = try Row.fetchOne(db, sql: """
                SELECT day, summary FROM journal_entries
                WHERE summary IS NOT NULL AND summary != ''
                  AND day >= ?
                ORDER BY day DESC
                LIMIT 1
            """, arguments: [cutoffDay]) else { return nil }

            guard let day: String = row["day"],
                  let summary: String = row["summary"] else { return nil }

            return (day, summary)
        }
    }

    /// Fetch the most recent N journal summaries, optionally excluding a specific day
    /// Returns array of (day, summary) tuples ordered by most recent first
    func fetchRecentJournalSummaries(count: Int, excludingDay: String? = nil) -> [(day: String, summary: String)] {
        return (try? timedRead("fetchRecentJournalSummaries") { db in
            var sql = """
                SELECT day, summary FROM journal_entries
                WHERE summary IS NOT NULL AND summary != ''
            """
            var arguments: [String] = []

            if let excludeDay = excludingDay {
                sql += " AND day != ?"
                arguments.append(excludeDay)
            }

            sql += " ORDER BY day DESC LIMIT ?"
            arguments.append(String(count))

            let rows = try Row.fetchAll(db, sql: sql, arguments: StatementArguments(arguments))

            return rows.compactMap { row -> (day: String, summary: String)? in
                guard let day: String = row["day"],
                      let summary: String = row["summary"] else { return nil }
                return (day, summary)
            }
        }) ?? []
    }

    /// Check if a day has intentions set (not just draft)
    func hasIntentionsForDay(_ day: String) -> Bool {
        return (try? timedRead("hasIntentionsForDay") { db in
            let count = try Int.fetchOne(db, sql: """
                SELECT COUNT(*) FROM journal_entries
                WHERE day = ? AND status IN ('intentions_set', 'complete')
            """, arguments: [day]) ?? 0
            return count > 0
        }) ?? false
    }

    /// Fetch the most recent long-term goals from any previous journal entry
    func fetchMostRecentGoals() -> String? {
        return try? timedRead("fetchMostRecentGoals") { db in
            let row = try Row.fetchOne(db, sql: """
                SELECT goals FROM journal_entries
                WHERE goals IS NOT NULL AND goals != ''
                ORDER BY day DESC
                LIMIT 1
            """)
            return row?["goals"]
        }
    }

    /// Check if a day has at least 1 hour of timeline activity
    func hasMinimumTimelineActivity(forDay day: String, minimumMinutes: Int = 60) -> Bool {
        guard let dayDate = dateFormatter.date(from: day) else { return false }

        let calendar = Calendar.current

        // Get 4 AM boundaries
        var startComponents = calendar.dateComponents([.year, .month, .day], from: dayDate)
        startComponents.hour = 4
        startComponents.minute = 0
        startComponents.second = 0
        guard let dayStart = calendar.date(from: startComponents) else { return false }

        guard let nextDay = calendar.date(byAdding: .day, value: 1, to: dayDate) else { return false }
        var endComponents = calendar.dateComponents([.year, .month, .day], from: nextDay)
        endComponents.hour = 4
        endComponents.minute = 0
        endComponents.second = 0
        guard let dayEnd = calendar.date(from: endComponents) else { return false }

        let startTs = Int(dayStart.timeIntervalSince1970)
        let endTs = Int(dayEnd.timeIntervalSince1970)

        // Sum total duration of timeline cards for the day
        let totalMinutes: Int? = try? timedRead("hasMinimumTimelineActivity") { db in
            // Calculate sum of (end_ts - start_ts) for all cards, converted to minutes
            let result = try Int.fetchOne(db, sql: """
                SELECT COALESCE(SUM(end_ts - start_ts), 0) / 60 as total_minutes
                FROM timeline_cards
                WHERE start_ts >= ? AND start_ts < ?
                  AND is_deleted = 0
            """, arguments: [startTs, endTs])
            return result
        }

        return (totalMinutes ?? 0) >= minimumMinutes
    }

    /// Fetch list of days that have journal entries (for navigation)
    func fetchJournalDays(limit: Int = 30) -> [String] {
        return (try? timedRead("fetchJournalDays") { db in
            try String.fetchAll(db, sql: """
                SELECT day FROM journal_entries
                ORDER BY day DESC
                LIMIT ?
            """, arguments: [limit])
        }) ?? []
    }


    private let purgeQ = DispatchQueue(label: "com.dayflow.storage.purge", qos: .background)
    private var purgeTimer: DispatchSourceTimer?
    private var checkpointTimer: DispatchSourceTimer?

    // MARK: - WAL Checkpoint

    /// Checkpoint the WAL file to merge changes into the main database.
    /// This prevents WAL from growing unbounded and reduces data loss risk on crash.
    /// - Parameter mode: .passive (non-blocking), .full, .restart, or .truncate (resets WAL to zero)
    func checkpoint(mode: Database.CheckpointMode = .passive) {
        do {
            _ = try db.writeWithoutTransaction { db in
                try db.checkpoint(mode)
            }
            print("‚úÖ [StorageManager] WAL checkpoint completed (mode: \(mode))")
        } catch {
            print("‚ö†Ô∏è [StorageManager] WAL checkpoint failed: \(error)")
            // Log to Sentry for visibility
            let breadcrumb = Breadcrumb(level: .warning, category: "database")
            breadcrumb.message = "WAL checkpoint failed"
            breadcrumb.data = ["mode": "\(mode)", "error": "\(error)"]
            SentryHelper.addBreadcrumb(breadcrumb)
        }
    }

    private func startCheckpointScheduler() {
        let timer = DispatchSource.makeTimerSource(queue: dbWriteQueue)
        timer.schedule(deadline: .now() + 300, repeating: 300) // Every 5 minutes
        timer.setEventHandler { [weak self] in
            self?.checkpoint(mode: .passive)
        }
        timer.resume()
        checkpointTimer = timer
    }

    // MARK: - Safe Database Initialization

    /// Opens the database with automatic recovery from backup if corrupted.
    /// Order of attempts: 1) Normal open, 2) Restore from most recent backup, 3) Fresh database
    private static func openDatabaseSafely(
        at dbURL: URL,
        backupsDir: URL,
        config: Configuration,
        fileManager: FileManager
    ) -> DatabasePool {
        // Attempt 1: Normal open
        do {
            let pool = try DatabasePool(path: dbURL.path, configuration: config)
            print("‚úÖ [StorageManager] Database opened successfully")
            return pool
        } catch {
            print("‚ö†Ô∏è [StorageManager] Failed to open database: \(error)")

            let breadcrumb = Breadcrumb(level: .error, category: "database")
            breadcrumb.message = "Database open failed, attempting recovery"
            breadcrumb.data = ["error": "\(error)"]
            SentryHelper.addBreadcrumb(breadcrumb)

            // Attempt 2: Restore from most recent backup
            if let backupURL = findMostRecentBackup(in: backupsDir, fileManager: fileManager) {
                print("üîÑ [StorageManager] Attempting recovery from backup: \(backupURL.lastPathComponent)")

                // Remove corrupted database files
                let walURL = URL(fileURLWithPath: dbURL.path + "-wal")
                let shmURL = URL(fileURLWithPath: dbURL.path + "-shm")
                try? fileManager.removeItem(at: dbURL)
                try? fileManager.removeItem(at: walURL)
                try? fileManager.removeItem(at: shmURL)

                // Copy backup to database location
                do {
                    try fileManager.copyItem(at: backupURL, to: dbURL)
                    let pool = try DatabasePool(path: dbURL.path, configuration: config)
                    print("‚úÖ [StorageManager] Successfully recovered from backup")

                    let recoveryBreadcrumb = Breadcrumb(level: .info, category: "database")
                    recoveryBreadcrumb.message = "Database recovered from backup"
                    recoveryBreadcrumb.data = ["backup": backupURL.lastPathComponent]
                    SentryHelper.addBreadcrumb(recoveryBreadcrumb)

                    return pool
                } catch {
                    print("‚ùå [StorageManager] Backup recovery failed: \(error)")
                }
            }

            // Attempt 3: Start fresh (last resort)
            print("üÜï [StorageManager] Starting with fresh database")
            let walURL = URL(fileURLWithPath: dbURL.path + "-wal")
            let shmURL = URL(fileURLWithPath: dbURL.path + "-shm")
            try? fileManager.removeItem(at: dbURL)
            try? fileManager.removeItem(at: walURL)
            try? fileManager.removeItem(at: shmURL)

            do {
                let pool = try DatabasePool(path: dbURL.path, configuration: config)

                let freshBreadcrumb = Breadcrumb(level: .warning, category: "database")
                freshBreadcrumb.message = "Started with fresh database after all recovery attempts failed"
                SentryHelper.addBreadcrumb(freshBreadcrumb)

                return pool
            } catch {
                // This is truly fatal - can't even create a fresh database
                fatalError("[StorageManager] Cannot create database: \(error)")
            }
        }
    }

    /// Finds the most recent backup file in the backups directory
    private static func findMostRecentBackup(in backupsDir: URL, fileManager: FileManager) -> URL? {
        guard let contents = try? fileManager.contentsOfDirectory(
            at: backupsDir,
            includingPropertiesForKeys: [.creationDateKey],
            options: .skipsHiddenFiles
        ) else {
            return nil
        }

        let sqliteBackups = contents.filter { $0.pathExtension == "sqlite" }

        // Sort by creation date, newest first
        let sorted = sqliteBackups.sorted { url1, url2 in
            let date1 = (try? url1.resourceValues(forKeys: [.creationDateKey]).creationDate) ?? .distantPast
            let date2 = (try? url2.resourceValues(forKeys: [.creationDateKey]).creationDate) ?? .distantPast
            return date1 > date2
        }

        return sorted.first
    }

    // MARK: - Integrity Check

    /// Performs a quick integrity check on the database.
    /// Logs a warning if issues are found but doesn't stop app launch.
    private func performIntegrityCheck() {
        do {
            let result = try db.read { db -> String? in
                try String.fetchOne(db, sql: "PRAGMA quick_check")
            }

            if result == "ok" {
                print("‚úÖ [StorageManager] Database integrity check passed")
            } else {
                print("‚ö†Ô∏è [StorageManager] Database integrity issues: \(result ?? "unknown")")

                let breadcrumb = Breadcrumb(level: .warning, category: "database")
                breadcrumb.message = "Database integrity check found issues"
                breadcrumb.data = ["result": result ?? "unknown"]
                SentryHelper.addBreadcrumb(breadcrumb)
            }
        } catch {
            print("‚ö†Ô∏è [StorageManager] Integrity check failed: \(error)")

            let breadcrumb = Breadcrumb(level: .error, category: "database")
            breadcrumb.message = "Database integrity check error"
            breadcrumb.data = ["error": "\(error)"]
            SentryHelper.addBreadcrumb(breadcrumb)
        }
    }

    // MARK: - Backup System

    private var backupTimer: DispatchSourceTimer?

    /// Creates a backup of the database using GRDB's native backup API.
    /// Backups are stored with timestamp in filename and old backups are pruned.
    func createBackup() {
        dbWriteQueue.async { [weak self] in
            guard let self = self else { return }

            let formatter = DateFormatter()
            formatter.dateFormat = "yyyy-MM-dd_HHmmss"
            let timestamp = formatter.string(from: Date())
            let backupName = "chunks-\(timestamp).sqlite"
            let backupURL = self.backupsDir.appendingPathComponent(backupName)

            do {
                // Create destination database for backup
                let destination = try DatabaseQueue(path: backupURL.path)

                // Use GRDB's native backup API
                try self.db.backup(to: destination)

                print("‚úÖ [StorageManager] Backup created: \(backupName)")

                let breadcrumb = Breadcrumb(level: .info, category: "database")
                breadcrumb.message = "Database backup created"
                breadcrumb.data = ["filename": backupName]
                SentryHelper.addBreadcrumb(breadcrumb)

                // Prune old backups, keeping last 3
                self.pruneOldBackups(keeping: 3)

            } catch {
                print("‚ùå [StorageManager] Backup failed: \(error)")

                let breadcrumb = Breadcrumb(level: .error, category: "database")
                breadcrumb.message = "Database backup failed"
                breadcrumb.data = ["error": "\(error)"]
                SentryHelper.addBreadcrumb(breadcrumb)
            }
        }
    }

    /// Removes old backups, keeping only the most recent `count` backups.
    private func pruneOldBackups(keeping count: Int) {
        guard let contents = try? fileMgr.contentsOfDirectory(
            at: backupsDir,
            includingPropertiesForKeys: [.creationDateKey],
            options: .skipsHiddenFiles
        ) else {
            return
        }

        let sqliteBackups = contents.filter { $0.pathExtension == "sqlite" }

        // Sort by creation date, newest first
        let sorted = sqliteBackups.sorted { url1, url2 in
            let date1 = (try? url1.resourceValues(forKeys: [.creationDateKey]).creationDate) ?? .distantPast
            let date2 = (try? url2.resourceValues(forKeys: [.creationDateKey]).creationDate) ?? .distantPast
            return date1 > date2
        }

        // Remove all but the newest `count` backups
        if sorted.count > count {
            let toDelete = sorted.dropFirst(count)
            for url in toDelete {
                try? fileMgr.removeItem(at: url)
                print("üóëÔ∏è [StorageManager] Pruned old backup: \(url.lastPathComponent)")
            }
        }
    }

    /// Schedules daily backups (every 24 hours, starting 1 hour after launch)
    private func startBackupScheduler() {
        let timer = DispatchSource.makeTimerSource(queue: dbWriteQueue)
        // First backup 1 hour after launch, then every 24 hours
        timer.schedule(deadline: .now() + 3600, repeating: 86400)
        timer.setEventHandler { [weak self] in
            self?.createBackup()
        }
        timer.resume()
        backupTimer = timer

        // Also create an immediate backup on first launch if none exists
        if Self.findMostRecentBackup(in: backupsDir, fileManager: fileMgr) == nil {
            createBackup()
        }
    }

    private func startPurgeScheduler() {
        let timer = DispatchSource.makeTimerSource(queue: purgeQ)
        timer.schedule(deadline: .now() + 3600, repeating: 3600) // Every hour
        timer.setEventHandler { [weak self] in
            self?.purgeIfNeeded()
            TimelapseStorageManager.shared.purgeIfNeeded()
        }
        timer.resume()
        purgeTimer = timer
    }

    private func purgeIfNeeded() {
        purgeQ.async { [weak self] in
            guard let self = self else { return }
            self.performPurgeIfNeeded()
        }
    }

    func purgeNow(completion: (() -> Void)? = nil) {
        purgeQ.async { [weak self] in
            guard let self = self else {
                if let completion {
                    DispatchQueue.main.async { completion() }
                }
                return
            }
            self.performPurgeIfNeeded()
            if let completion {
                DispatchQueue.main.async { completion() }
            }
        }
    }

    private func performPurgeIfNeeded() {
        do {
            let limit = StoragePreferences.recordingsLimitBytes

            if limit == Int64.max {
                return // Unlimited storage - skip purge
            }

            cleanupRecordingStragglers()

            // Check current size after cleaning orphans
            let currentSize = try fileMgr.allocatedSizeOfDirectory(at: root)

            // Clean up if above limit
            if currentSize > limit {
                var freedSpace: Int64 = 0
                var passCount = 0

                while currentSize - freedSpace > limit {
                    var deletedThisPass = 0
                    var freedThisPass: Int64 = 0

                    try timedWrite("purgeScreenshots") { db in
                        // Get oldest active screenshots
                        let oldScreenshots = try Row.fetchAll(db, sql: """
                            SELECT id, file_path, file_size
                            FROM screenshots
                            WHERE is_deleted = 0
                            ORDER BY captured_at ASC
                            LIMIT 500
                        """)

                        guard !oldScreenshots.isEmpty else { return }

                        for screenshot in oldScreenshots {
                            guard let id: Int64 = screenshot["id"],
                                  let path: String = screenshot["file_path"] else { continue }

                            // Mark as deleted in DB first (safer ordering)
                            try db.execute(sql: """
                                UPDATE screenshots
                                SET is_deleted = 1
                                WHERE id = ?
                            """, arguments: [id])

                            // Then delete physical file
                            if fileMgr.fileExists(atPath: path) {
                                var fileSize: Int64 = 0
                                if let storedSize: Int64 = screenshot["file_size"] {
                                    fileSize = storedSize
                                }
                                if fileSize == 0,
                                   let attrs = try? fileMgr.attributesOfItem(atPath: path),
                                   let size = attrs[.size] as? NSNumber {
                                    fileSize = size.int64Value
                                }

                                do {
                                    try fileMgr.removeItem(atPath: path)
                                    freedThisPass += fileSize
                                    deletedThisPass += 1
                                } catch {
                                    print("‚ö†Ô∏è Failed to delete screenshot at \(path): \(error)")
                                }
                            } else {
                                deletedThisPass += 1
                            }
                        }
                    }

                    if deletedThisPass == 0 {
                        break
                    }

                    freedSpace += freedThisPass
                    passCount += 1

                    if passCount > 200 {
                        break
                    }
                }
            }

            cleanupRecordingStragglers()
        } catch {
            print("‚ùå Purge error: \(error)")
        }
    }

    private func cleanupRecordingStragglers() {
        // Delete any recordings that are not referenced by active screenshots.
        let activeScreenshotPaths: Set<String> = Set((try? timedRead("activeScreenshotPaths") { db in
            try Row.fetchAll(db, sql: """
                SELECT file_path
                FROM screenshots
                WHERE is_deleted = 0
            """)
            .compactMap { $0["file_path"] as? String }
        }) ?? [])

        guard let enumerator = fileMgr.enumerator(
            at: root,
            includingPropertiesForKeys: [.isDirectoryKey],
            options: [.skipsHiddenFiles]
        ) else { return }

        let deleteAll = activeScreenshotPaths.isEmpty

        for case let fileURL as URL in enumerator {
            do {
                let values = try fileURL.resourceValues(forKeys: [.isDirectoryKey])
                if values.isDirectory == true { continue }

                if deleteAll || !activeScreenshotPaths.contains(fileURL.path) {
                    try fileMgr.removeItem(at: fileURL)
                }
            } catch {
                print("‚ö†Ô∏è Failed to delete straggler file at \(fileURL.path): \(error)")
            }
        }
    }
}


private extension StorageManager {
    func migrateLegacyChunkPathsIfNeeded() {
        guard let bundleID = Bundle.main.bundleIdentifier else { return }
        guard let appSupport = fileMgr.urls(for: .applicationSupportDirectory, in: .userDomainMask).first else { return }

        let legacyBase = fileMgr.homeDirectoryForCurrentUser
            .appendingPathComponent("Library/Containers/\(bundleID)/Data/Library/Application Support/Dayflow", isDirectory: true)
        let newBase = appSupport.appendingPathComponent("Dayflow", isDirectory: true)

        guard legacyBase.path != newBase.path else { return }

        func normalizedPrefix(_ path: String) -> String {
            path.hasSuffix("/") ? path : path + "/"
        }

        let legacyRecordings = normalizedPrefix(legacyBase.appendingPathComponent("recordings", isDirectory: true).path)
        let newRecordings = normalizedPrefix(root.path)

        let legacyTimelapses = normalizedPrefix(legacyBase.appendingPathComponent("timelapses", isDirectory: true).path)
        let newTimelapses = normalizedPrefix(newBase.appendingPathComponent("timelapses", isDirectory: true).path)

        let replacements: [(label: String, table: String, column: String, legacyPrefix: String, newPrefix: String)] = [
            ("chunk file paths", "chunks", "file_url", legacyRecordings, newRecordings),
            ("timelapse video paths", "timeline_cards", "video_summary_url", legacyTimelapses, newTimelapses)
        ]

        do {
            try timedWrite("migrateLegacyFileURLs") { db in
                for replacement in replacements {
                    guard replacement.legacyPrefix != replacement.newPrefix else { continue }

                    let pattern = replacement.legacyPrefix + "%"
                    let count = try Int.fetchOne(
                        db,
                        sql: "SELECT COUNT(*) FROM \(replacement.table) WHERE \(replacement.column) LIKE ?",
                        arguments: [pattern]
                    ) ?? 0

                    guard count > 0 else { continue }

                    try db.execute(
                        sql: """
                            UPDATE \(replacement.table)
                            SET \(replacement.column) = REPLACE(\(replacement.column), ?, ?)
                            WHERE \(replacement.column) LIKE ?
                        """,
                        arguments: [replacement.legacyPrefix, replacement.newPrefix, pattern]
                    )

                    let updated = db.changesCount
                    print("‚ÑπÔ∏è StorageManager: migrated \(updated) \(replacement.label) to \(replacement.newPrefix)")
                }
            }
        } catch {
            print("‚ö†Ô∏è StorageManager: failed to migrate legacy file URLs: \(error)")
        }
    }

    static func migrateDatabaseLocationIfNeeded(
        fileManager: FileManager,
        legacyRecordingsDir: URL,
        newDatabaseURL: URL
    ) {
        let destinationDir = newDatabaseURL.deletingLastPathComponent()
        let filenames = ["chunks.sqlite", "chunks.sqlite-wal", "chunks.sqlite-shm"]

        guard filenames.contains(where: { fileManager.fileExists(atPath: legacyRecordingsDir.appendingPathComponent($0).path) }) else {
            return
        }

        if !fileManager.fileExists(atPath: destinationDir.path) {
            try? fileManager.createDirectory(at: destinationDir, withIntermediateDirectories: true)
        }

        for name in filenames {
            let legacyURL = legacyRecordingsDir.appendingPathComponent(name)
            guard fileManager.fileExists(atPath: legacyURL.path) else { continue }

            let destinationURL = destinationDir.appendingPathComponent(name)
            do {
                if fileManager.fileExists(atPath: destinationURL.path) {
                    try fileManager.removeItem(at: destinationURL)
                }
                try fileManager.moveItem(at: legacyURL, to: destinationURL)
                print("‚ÑπÔ∏è StorageManager: migrated \(name) to \(destinationURL.path)")
            } catch {
                print("‚ö†Ô∏è StorageManager: failed to migrate \(name): \(error)")
            }
        }
    }
}


extension FileManager {
    func allocatedSizeOfDirectory(at url: URL) throws -> Int64 {
        guard let enumerator = enumerator(
            at: url,
            includingPropertiesForKeys: [.totalFileAllocatedSizeKey, .isDirectoryKey],
            options: [.skipsHiddenFiles]
        ) else { return 0 }

        var total: Int64 = 0
        for case let fileURL as URL in enumerator {
            do {
                let values = try fileURL.resourceValues(forKeys: [.totalFileAllocatedSizeKey, .isDirectoryKey])
                if values.isDirectory == true {
                    // Directories report 0, rely on enumerator to traverse contents
                    continue
                }
                total += Int64(values.totalFileAllocatedSize ?? 0)
            } catch {
                continue
            }
        }
        return total
    }
}
